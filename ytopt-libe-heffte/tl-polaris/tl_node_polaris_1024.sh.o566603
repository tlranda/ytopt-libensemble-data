Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Modify PS1
Calling on 4 workers with 4 mpi ranks per worker for size 1024
Sat 05 Aug 2023 05:34:37 AM UTC
python libEwrapper.py --mpi-ranks 4 --worker-timeout 300 --application-scale 1024 --gpu-enabled --ensemble-workers 4 --max-evals 30 --configure-environment craympi --machine-identifier polaris-gpu --system polaris --ens-dir-path Polaris_TL_nodes_4r_1024a --ens-template run_gctla.py --ens-script qsub_tl.batch --gc-input logs/PolarisSourceTasks/*n_1024a/manager_results.csv --gc-ignore logs/PolarisSourceTasks/Polaris_01n_1024a/manager_results.csv --gc-initial-quantile 0.8 --launch-job --display-results
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
x3202c0s25b0n0
Sat 05 Aug 2023 05:34:37 AM UTC

python run_gctla_321554dc.py --comms local --nworkers 5 --learner=RF --max-evals 30  --constraint-sys 4 --constraint-app 1024 --input logs/PolarisSourceTasks/Polaris_01n_1024a/manager_results.csv logs/PolarisSourceTasks/Polaris_02n_1024a/manager_results.csv logs/PolarisSourceTasks/Polaris_04n_1024a/manager_results.csv logs/PolarisSourceTasks/Polaris_08n_1024a/manager_results.csv logs/PolarisSourceTasks/Polaris_16n_1024a/manager_results.csv --auto-budget=False --ignore logs/PolarisSourceTasks/Polaris_01n_1024a/manager_results.csv --predictions-only False --initial-quantile 0.8
This ensemble operates as: ./ensemble_Polaris_TL_nodes_4r_1024a_14e4d4f6

Detected 64 CPU threads on this machine
Detected 4 GPUs on this machine
Set ranks_per_node to 4

APP_SCALE (AKA Problem Size X, X, X) = 1024 x3
MPI_RANKS (AKA System Size X * Y = Z) = 1 * 4 = 4
Depths are based on 64 threads on each node, shared across 4 MPI ranks on each node
Selectable depths are: [2, 4, 8, 12, 16]

Identifying machine as polaris-gpu

GC will be fitted against data from: ['logs/PolarisSourceTasks/Polaris_02n_1024a/manager_results.csv', 'logs/PolarisSourceTasks/Polaris_04n_1024a/manager_results.csv', 'logs/PolarisSourceTasks/Polaris_08n_1024a/manager_results.csv', 'logs/PolarisSourceTasks/Polaris_16n_1024a/manager_results.csv']
Using max-evals: 30
tmp_files
tmp_files
tmp_files
tmp_files
Copy LibEnsemble template --> run_gctla_321554dc.py
Failed to copy Job script <-- qsub_tl.batch
Set ('ens_dir_path',) to ('"Polaris_TL_nodes_4r_1024a_14e4d4f6"',) in run_gctla_321554dc.py
  -- SED OK
Set ('machine_identifier',) to ('"polaris-gpu"',) in run_gctla_321554dc.py
  -- SED OK
Set ('seed_configspace',) to (1234,) in run_gctla_321554dc.py
  -- SED OK
Set ('seed_ytopt',) to (2345,) in run_gctla_321554dc.py
  -- SED OK
Set ('seed_numpy',) to (1,) in run_gctla_321554dc.py
  -- SED OK
Set ('mpi_ranks',) to (4,) in run_gctla_321554dc.py
  -- SED OK
Set ('worker_timeout',) to (300,) in run_gctla_321554dc.py
  -- SED OK
Set ('application_scale',) to (1024,) in run_gctla_321554dc.py
  -- SED OK
Set ('cpu_override',) to ('None',) in run_gctla_321554dc.py
  -- SED OK
Set ('cpu_ranks_per_node',) to ('64',) in run_gctla_321554dc.py
  -- SED OK
Set ('gpu_enabled',) to ('True',) in run_gctla_321554dc.py
  -- SED OK
Produce job script qsub_tl_720b4888.batch
Script written
Job script migrated --> ensemble_Polaris_TL_nodes_4r_1024a_14e4d4f6/qsub_tl_720b4888.batch
LibEnsemble driver migrated --> ensemble_Polaris_TL_nodes_4r_1024a_14e4d4f6/run_gctla_321554dc.py
Ensemble logs could not be migrated <-- ensemble.log
Ytopt logs could not be migrated <-- ytopt.log
Manager Results unavailable
No unfinished evaluations to view
Job script could not be migrated <-- qsub_tl_720b4888.batch
LibEnsemble driver could not be migrated <-- run_gctla_321554dc.py
Ensemble logs could not be migrated <-- ensemble.log
Ytopt logs could not be migrated <-- ytopt.log
