“RANK= 6 LOCAL_RANK= 2 gpu= 1”
“RANK= 5 LOCAL_RANK= 1 gpu= 2”
“RANK= 7 LOCAL_RANK= 3 gpu= 0”
“RANK= 4 LOCAL_RANK= 0 gpu= 3”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft double 64 64 64 -a2av -slabs -r2c_dir 2 -ingrid 8 1 1 -outgrid 8 1 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft double 64 64 64 -a2av -slabs -r2c_dir 2 -ingrid 8 1 1 -outgrid 8 1 1 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft double 64 64 64 -a2av -slabs -r2c_dir 2 -ingrid 8 1 1 -outgrid 8 1 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft double 64 64 64 -a2av -slabs -r2c_dir 2 -ingrid 8 1 1 -outgrid 8 1 1 -n5
“RANK= 0 LOCAL_RANK= 0 gpu= 3”
“RANK= 1 LOCAL_RANK= 1 gpu= 2”
“RANK= 2 LOCAL_RANK= 2 gpu= 1”
“RANK= 3 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft double 64 64 64 -a2av -slabs -r2c_dir 2 -ingrid 8 1 1 -outgrid 8 1 1 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft double 64 64 64 -a2av -slabs -r2c_dir 2 -ingrid 8 1 1 -outgrid 8 1 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
Shell debugging restarted
+ unset __lmod_vx
+ unset __lmod_vx
+ speed3d_r2c cufft double 64 64 64 -a2av -slabs -r2c_dir 2 -ingrid 8 1 1 -outgrid 8 1 1 -n5
+ speed3d_r2c cufft double 64 64 64 -a2av -slabs -r2c_dir 2 -ingrid 8 1 1 -outgrid 8 1 1 -n5
MPICH ERROR [Rank 6] [job id 58d3b336-a105-4006-96a2-e7540a21e3df] [Thu Nov  9 14:09:50 2023] [x3111c0s1b0n0] - Abort(808524431) (rank 6 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1465c3600000, scnts=0x1effcb0, sdispls=0x1efff90, dtype=0x4c001041, rbuf=0x1465c3642000, rcnts=0x1ea4510, rdispls=0x1ea4540, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1465c3600000, scnts=0x1effcb0, sdispls=0x1efff90, dtype=0x4c001041, rbuf=0x1465c3642000, rcnts=0x1ea4510, rdispls=0x1ea4540, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 5] [job id 58d3b336-a105-4006-96a2-e7540a21e3df] [Thu Nov  9 14:09:50 2023] [x3111c0s1b0n0] - Abort(875633295) (rank 5 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1460db600000, scnts=0x212cc50, sdispls=0x212cf30, dtype=0x4c001041, rbuf=0x1460db642000, rcnts=0x20d1560, rdispls=0x20d1590, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1460db600000, scnts=0x212cc50, sdispls=0x212cf30, dtype=0x4c001041, rbuf=0x1460db642000, rcnts=0x20d1560, rdispls=0x20d1590, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 4] [job id 58d3b336-a105-4006-96a2-e7540a21e3df] [Thu Nov  9 14:09:50 2023] [x3111c0s1b0n0] - Abort(405871247) (rank 4 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x146c91600000, scnts=0x15738b0, sdispls=0x1573b90, dtype=0x4c001041, rbuf=0x146c91642000, rcnts=0x1554560, rdispls=0x1554590, datatype=dtype=0x4c001041, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x146c91600000, scnts=0x15738b0, sdispls=0x1573b90, dtype=0x4c001041, rbuf=0x146c91642000, rcnts=0x1554560, rdispls=0x1554590, datatype=dtype=0x4c001041, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 3] [job id 58d3b336-a105-4006-96a2-e7540a21e3df] [Thu Nov  9 14:09:50 2023] [x3111c0s19b1n0] - Abort(472980111) (rank 3 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x149ae1600000, scnts=0x1321640, sdispls=0x1321920, dtype=0x4c001041, rbuf=0x149ae1642000, rcnts=0x1321bd0, rdispls=0x1321c00, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x149ae1600000, scnts=0x1321640, sdispls=0x1321920, dtype=0x4c001041, rbuf=0x149ae1642000, rcnts=0x1321bd0, rdispls=0x1321c00, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 1] [job id 58d3b336-a105-4006-96a2-e7540a21e3df] [Thu Nov  9 14:09:50 2023] [x3111c0s19b1n0] - Abort(808524431) (rank 1 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14aa93600000, scnts=0xdae980, sdispls=0xdaec60, dtype=0x4c001041, rbuf=0x14aa93642000, rcnts=0xdaef10, rdispls=0xdaef40, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14aa93600000, scnts=0xdae980, sdispls=0xdaec60, dtype=0x4c001041, rbuf=0x14aa93642000, rcnts=0xdaef10, rdispls=0xdaef40, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
x3111c0s1b0n0.hsn.cm.polaris.alcf.anl.gov: rank 6 exited with code 255
MPICH ERROR [Rank 0] [job id 58d3b336-a105-4006-96a2-e7540a21e3df] [Thu Nov  9 14:09:50 2023] [x3111c0s19b1n0] - Abort(405871247) (rank 0 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f01b600000, scnts=0x1ac1610, sdispls=0x1ac18f0, dtype=0x4c001041, rbuf=0x14f01b642000, rcnts=0x1ac1e30, rdispls=0x1ac1e60, datatype=dtype=0x4c001041, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f01b600000, scnts=0x1ac1610, sdispls=0x1ac18f0, dtype=0x4c001041, rbuf=0x14f01b642000, rcnts=0x1ac1e30, rdispls=0x1ac1e60, datatype=dtype=0x4c001041, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 2] [job id 58d3b336-a105-4006-96a2-e7540a21e3df] [Thu Nov  9 14:09:50 2023] [x3111c0s19b1n0] - Abort(808524431) (rank 2 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14899b600000, scnts=0xe8b980, sdispls=0xe8bc60, dtype=0x4c001041, rbuf=0x14899b642000, rcnts=0xe8bf10, rdispls=0xe8bf40, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14899b600000, scnts=0xe8b980, sdispls=0xe8bc60, dtype=0x4c001041, rbuf=0x14899b642000, rcnts=0xe8bf10, rdispls=0xe8bf40, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
