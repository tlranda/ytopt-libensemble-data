“RANK= 16 LOCAL_RANK= 0 gpu= 3”
“RANK= 18 LOCAL_RANK= 2 gpu= 1”
“RANK= 17 LOCAL_RANK= 1 gpu= 2”
“RANK= 19 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
“RANK= 28 LOCAL_RANK= 0 gpu= 3”
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
Shell debugging restarted
“RANK= 30 LOCAL_RANK= 2 gpu= 1”
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
“RANK= 29 LOCAL_RANK= 1 gpu= 2”
“RANK= 31 LOCAL_RANK= 3 gpu= 0”
“RANK= 21 LOCAL_RANK= 1 gpu= 2”
“RANK= 20 LOCAL_RANK= 0 gpu= 3”
“RANK= 22 LOCAL_RANK= 2 gpu= 1”
“RANK= 23 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
Shell debugging restarted
+ unset __lmod_vx
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
“RANK= 0 LOCAL_RANK= 0 gpu= 3”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
“RANK= 1 LOCAL_RANK= 1 gpu= 2”
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
“RANK= 2 LOCAL_RANK= 2 gpu= 1”
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
“RANK= 3 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
Shell debugging restarted
Shell debugging restarted
+ unset __lmod_vx
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
“RANK= 24 LOCAL_RANK= 0 gpu= 3”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
“RANK= 12 LOCAL_RANK= 0 gpu= 3”
“RANK= 25 LOCAL_RANK= 1 gpu= 2”
“RANK= 14 LOCAL_RANK= 2 gpu= 1”
“RANK= 26 LOCAL_RANK= 2 gpu= 1”
“RANK= 27 LOCAL_RANK= 3 gpu= 0”
Shell debugging restarted
“RANK= 13 LOCAL_RANK= 1 gpu= 2”
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
“RANK= 15 LOCAL_RANK= 3 gpu= 0”
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
“RANK= 8 LOCAL_RANK= 0 gpu= 3”
Shell debugging restarted
+ unset __lmod_vx
“RANK= 9 LOCAL_RANK= 1 gpu= 2”
“RANK= 10 LOCAL_RANK= 2 gpu= 1”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
Shell debugging restarted
+ unset __lmod_vx
“RANK= 11 LOCAL_RANK= 3 gpu= 0”
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
“RANK= 4 LOCAL_RANK= 0 gpu= 3”
“RANK= 5 LOCAL_RANK= 1 gpu= 2”
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
“RANK= 7 LOCAL_RANK= 3 gpu= 0”
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
“RANK= 6 LOCAL_RANK= 2 gpu= 1”
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 0 -ingrid 16 2 1 -n5
MPICH ERROR [Rank 27] [job id b0ae3642-68e8-4b9e-9c50-67753b74245a] [Fri Aug  4 06:11:48 2023] [x3202c0s37b1n0] - Abort(741415567) (rank 27 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14cd34000000, scnts=0x1f5f9f0, sdispls=0x1f7c480, dtype=0x4c000840, rbuf=0x14cd34200000, rcnts=0x1f7c5a0, rdispls=0x1f7c630, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14cd34000000, scnts=0x1f5f9f0, sdispls=0x1f7c480, dtype=0x4c000840, rbuf=0x14cd34200000, rcnts=0x1f7c5a0, rdispls=0x1f7c630, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 17] [job id b0ae3642-68e8-4b9e-9c50-67753b74245a] [Fri Aug  4 06:11:48 2023] [x3202c0s31b1n0] - Abort(271653519) (rank 17 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147644000000, scnts=0x10c54a0, sdispls=0x10c5d70, dtype=0x4c000840, rbuf=0x147644200000, rcnts=0x10c5e90, rdispls=0x10c5f20, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147644000000, scnts=0x10c54a0, sdispls=0x10c5d70, dtype=0x4c000840, rbuf=0x147644200000, rcnts=0x10c5e90, rdispls=0x10c5f20, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 14] [job id b0ae3642-68e8-4b9e-9c50-67753b74245a] [Fri Aug  4 06:11:48 2023] [x3202c0s31b0n0] - Abort(472980111) (rank 14 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15304e000000, scnts=0x22c6360, sdispls=0x22c6c30, dtype=0x4c000840, rbuf=0x15304e208000, rcnts=0x22c6d50, rdispls=0x22c6de0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15304e000000, scnts=0x22c6360, sdispls=0x22c6c30, dtype=0x4c000840, rbuf=0x15304e208000, rcnts=0x22c6d50, rdispls=0x22c6de0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 12] [job id b0ae3642-68e8-4b9e-9c50-67753b74245a] [Fri Aug  4 06:11:48 2023] [x3202c0s31b0n0] - Abort(942742159) (rank 12 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14b734000000, scnts=0x258ef50, sdispls=0x258fab0, dtype=0x4c000840, rbuf=0x14b734208000, rcnts=0x258fbd0, rdispls=0x258fc60, datatype=dtype=0x4c000840, comm=comm=0xc4000009) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14b734000000, scnts=0x258ef50, sdispls=0x258fab0, dtype=0x4c000840, rbuf=0x14b734208000, rcnts=0x258fbd0, rdispls=0x258fc60, datatype=dtype=0x4c000840, comm=comm=0xc4000009) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 10] [job id b0ae3642-68e8-4b9e-9c50-67753b74245a] [Fri Aug  4 06:11:48 2023] [x3202c0s25b1n0] - Abort(674306703) (rank 10 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15282c000000, scnts=0x15184a0, sdispls=0x1518d70, dtype=0x4c000840, rbuf=0x15282c208000, rcnts=0x1518e90, rdispls=0x1518f20, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15282c000000, scnts=0x15184a0, sdispls=0x1518d70, dtype=0x4c000840, rbuf=0x15282c208000, rcnts=0x1518e90, rdispls=0x1518f20, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 26] [job id b0ae3642-68e8-4b9e-9c50-67753b74245a] [Fri Aug  4 06:11:48 2023] [x3202c0s37b1n0] - Abort(271653519) (rank 26 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14633c000000, scnts=0xbb6bf0, sdispls=0xbd3560, dtype=0x4c000840, rbuf=0x14633c208000, rcnts=0xbd3680, rdispls=0xbd3710, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14633c000000, scnts=0xbb6bf0, sdispls=0xbd3560, dtype=0x4c000840, rbuf=0x14633c208000, rcnts=0xbd3680, rdispls=0xbd3710, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 16] [job id b0ae3642-68e8-4b9e-9c50-67753b74245a] [Fri Aug  4 06:11:48 2023] [x3202c0s31b1n0] - Abort(405871247) (rank 16 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x151c14000000, scnts=0xfaa390, sdispls=0xfaaef0, dtype=0x4c000840, rbuf=0x151c14208000, rcnts=0xfccdd0, rdispls=0xfe6f20, datatype=dtype=0x4c000840, comm=comm=0xc4000009) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x151c14000000, scnts=0xfaa390, sdispls=0xfaaef0, dtype=0x4c000840, rbuf=0x151c14208000, rcnts=0xfccdd0, rdispls=0xfe6f20, datatype=dtype=0x4c000840, comm=comm=0xc4000009) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 22] [job id b0ae3642-68e8-4b9e-9c50-67753b74245a] [Fri Aug  4 06:11:48 2023] [x3202c0s37b0n0] - Abort(405871247) (rank 22 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14bc2c000000, scnts=0x2291400, sdispls=0x2291cd0, dtype=0x4c000840, rbuf=0x14bc2c208000, rcnts=0x2291df0, rdispls=0x2291e80, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14bc2c000000, scnts=0x2291400, sdispls=0x2291cd0, dtype=0x4c000840, rbuf=0x14bc2c208000, rcnts=0x2291df0, rdispls=0x2291e80, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 24] [job id b0ae3642-68e8-4b9e-9c50-67753b74245a] [Fri Aug  4 06:11:48 2023] [x3202c0s37b1n0] - Abort(137435791) (rank 24 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x146a0e000000, scnts=0x12edb30, sdispls=0x12ee690, dtype=0x4c000840, rbuf=0x146a0e208000, rcnts=0x12ee7b0, rdispls=0x12ee840, datatype=dtype=0x4c000840, comm=comm=0xc4000009) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

MPICH ERROR [Rank 11] [job id b0ae3642-68e8-4b9e-9c50-67753b74245a] [Fri Aug  4 06:11:48 2023] [x3202c0s25b1n0] - Abort(204544655) (rank 11 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14996e000000, scnts=0x2152450, sdispls=0x2152d20, dtype=0x4c000840, rbuf=0x14996e200000, rcnts=0x2152e40, rdispls=0x2152ed0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14996e000000, scnts=0x2152450, sdispls=0x2152d20, dtype=0x4c000840, rbuf=0x14996e200000, rcnts=0x2152e40, rdispls=0x2152ed0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x146a0e000000, scnts=0x12edb30, sdispls=0x12ee690, dtype=0x4c000840, rbuf=0x146a0e208000, rcnts=0x12ee7b0, rdispls=0x12ee840, datatype=dtype=0x4c000840, comm=comm=0xc4000009) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 30] [job id b0ae3642-68e8-4b9e-9c50-67753b74245a] [Fri Aug  4 06:11:48 2023] [x3202c0s7b0n0] - Abort(607197839) (rank 30 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x145cce000000, scnts=0xb3c450, sdispls=0xb3cd20, dtype=0x4c000840, rbuf=0x145cce208000, rcnts=0xb3ce40, rdispls=0xb3ced0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x145cce000000, scnts=0xb3c450, sdispls=0xb3cd20, dtype=0x4c000840, rbuf=0x145cce208000, rcnts=0xb3ce40, rdispls=0xb3ced0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 19] [job id b0ae3642-68e8-4b9e-9c50-67753b74245a] [Fri Aug  4 06:11:48 2023] [x3202c0s31b1n0] - Abort(1009851023) (rank 19 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x146d54000000, scnts=0x2295360, sdispls=0x2295be0, dtype=0x4c000840, rbuf=0x146d54200000, rcnts=0x2295d00, rdispls=0x2295d90, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x146d54000000, scnts=0x2295360, sdispls=0x2295be0, dtype=0x4c000840, rbuf=0x146d54200000, rcnts=0x2295d00, rdispls=0x2295d90, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 28] [job id b0ae3642-68e8-4b9e-9c50-67753b74245a] [Fri Aug  4 06:11:48 2023] [x3202c0s7b0n0] - Abort(271653519) (rank 28 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1513ac000000, scnts=0x2165470, sdispls=0x21a1f20, dtype=0x4c000840, rbuf=0x1513ac208000, rcnts=0x2180220, rdispls=0x21802b0, datatype=dtype=0x4c000840, comm=comm=0xc4000009) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1513ac000000, scnts=0x2165470, sdispls=0x21a1f20, dtype=0x4c000840, rbuf=0x1513ac208000, rcnts=0x2180220, rdispls=0x21802b0, datatype=dtype=0x4c000840, comm=comm=0xc4000009) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 20] [job id b0ae3642-68e8-4b9e-9c50-67753b74245a] [Fri Aug  4 06:11:48 2023] [x3202c0s37b0n0] - Abort(942742159) (rank 20 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150954000000, scnts=0x11e4150, sdispls=0x11e4cb0, dtype=0x4c000840, rbuf=0x150954208000, rcnts=0x11e4dd0, rdispls=0x11e4e60, datatype=dtype=0x4c000840, comm=comm=0xc4000009) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150954000000, scnts=0x11e4150, sdispls=0x11e4cb0, dtype=0x4c000840, rbuf=0x150954208000, rcnts=0x11e4dd0, rdispls=0x11e4e60, datatype=dtype=0x4c000840, comm=comm=0xc4000009) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
x3202c0s37b1n0.hsn.cm.polaris.alcf.anl.gov: rank 27 exited with code 255
