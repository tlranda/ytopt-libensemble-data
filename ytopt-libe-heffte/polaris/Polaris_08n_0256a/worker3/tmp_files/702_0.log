“RANK= 28 LOCAL_RANK= 0 gpu= 3”
“RANK= 31 LOCAL_RANK= 3 gpu= 0”
“RANK= 29 LOCAL_RANK= 1 gpu= 2”
“RANK= 30 LOCAL_RANK= 2 gpu= 1”
“RANK= 16 LOCAL_RANK= 0 gpu= 3”
“RANK= 17 LOCAL_RANK= 1 gpu= 2”
“RANK= 18 LOCAL_RANK= 2 gpu= 1”
“RANK= 19 LOCAL_RANK= 3 gpu= 0”
“RANK= 5 LOCAL_RANK= 1 gpu= 2”
“RANK= 6 LOCAL_RANK= 2 gpu= 1”
“RANK= 7 LOCAL_RANK= 3 gpu= 0”
“RANK= 4 LOCAL_RANK= 0 gpu= 3”
“RANK= 24 LOCAL_RANK= 0 gpu= 3”
“RANK= 25 LOCAL_RANK= 1 gpu= 2”
“RANK= 26 LOCAL_RANK= 2 gpu= 1”
“RANK= 27 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
“RANK= 0 LOCAL_RANK= 0 gpu= 3”
Shell debugging restarted
+ unset __lmod_vx
“RANK= 1 LOCAL_RANK= 1 gpu= 2”
Shell debugging restarted
“RANK= 2 LOCAL_RANK= 2 gpu= 1”
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
“RANK= 3 LOCAL_RANK= 3 gpu= 0”
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ '[' -z '' ']'
+ case "$-" in
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
“RANK= 8 LOCAL_RANK= 0 gpu= 3”
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
“RANK= 9 LOCAL_RANK= 1 gpu= 2”
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
“RANK= 10 LOCAL_RANK= 2 gpu= 1”
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
“RANK= 11 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
“RANK= 15 LOCAL_RANK= 3 gpu= 0”
“RANK= 12 LOCAL_RANK= 0 gpu= 3”
“RANK= 13 LOCAL_RANK= 1 gpu= 2”
“RANK= 14 LOCAL_RANK= 2 gpu= 1”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ '[' -n x ']'
+ set +x
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
“RANK= 20 LOCAL_RANK= 0 gpu= 3”
“RANK= 21 LOCAL_RANK= 1 gpu= 2”
“RANK= 22 LOCAL_RANK= 2 gpu= 1”
“RANK= 23 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
MPICH ERROR [Rank 31] [job id 5d7e5dbb-a394-468e-a274-18b6df8b6c41] [Tue Jul 25 02:57:45 2023] [x3112c0s1b0n0] - Abort(607197839) (rank 31 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1528c4000000, scnts=0x26f8af0, sdispls=0x26f8f90, dtype=0x4c000840, rbuf=0x1528c4200000, rcnts=0x26f8fd0, rdispls=0x26f8ff0, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1528c4000000, scnts=0x26f8af0, sdispls=0x26f8f90, dtype=0x4c000840, rbuf=0x1528c4200000, rcnts=0x26f8fd0, rdispls=0x26f8ff0, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 16] [job id 5d7e5dbb-a394-468e-a274-18b6df8b6c41] [Tue Jul 25 02:57:45 2023] [x3112c0s13b1n0] - Abort(607197839) (rank 16 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x152e02000000, scnts=0x9de5a0, sdispls=0x9dea40, dtype=0x4c000840, rbuf=0x152e02210000, rcnts=0x9dea80, rdispls=0x9deaa0, datatype=dtype=0x4c000840, comm=comm=0xc4000009) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x152e02000000, scnts=0x9de5a0, sdispls=0x9dea40, dtype=0x4c000840, rbuf=0x152e02210000, rcnts=0x9dea80, rdispls=0x9deaa0, datatype=dtype=0x4c000840, comm=comm=0xc4000009) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 17] [job id 5d7e5dbb-a394-468e-a274-18b6df8b6c41] [Tue Jul 25 02:57:45 2023] [x3112c0s13b1n0] - Abort(405871247) (rank 17 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15310e000000, scnts=0xbc6770, sdispls=0xbc6c10, dtype=0x4c000840, rbuf=0x15310e210000, rcnts=0xbc6c50, rdispls=0xbc6c70, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15310e000000, scnts=0xbc6770, sdispls=0xbc6c10, dtype=0x4c000840, rbuf=0x15310e210000, rcnts=0xbc6c50, rdispls=0xbc6c70, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 21] [job id 5d7e5dbb-a394-468e-a274-18b6df8b6c41] [Tue Jul 25 02:57:45 2023] [x3112c0s19b0n0] - Abort(741415567) (rank 21 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147c2e000000, scnts=0x1b39740, sdispls=0x1b39be0, dtype=0x4c000840, rbuf=0x147c2e200000, rcnts=0x1b39c20, rdispls=0x1b39c40, datatype=dtype=0x4c000840, comm=comm=0xc4000002) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147c2e000000, scnts=0x1b39740, sdispls=0x1b39be0, dtype=0x4c000840, rbuf=0x147c2e200000, rcnts=0x1b39c20, rdispls=0x1b39c40, datatype=dtype=0x4c000840, comm=comm=0xc4000002) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 5] [job id 5d7e5dbb-a394-468e-a274-18b6df8b6c41] [Tue Jul 25 02:57:45 2023] [x3111c0s7b0n0] - Abort(3218063) (rank 5 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14abca000000, scnts=0x118e410, sdispls=0x118e8b0, dtype=0x4c000840, rbuf=0x14abca200000, rcnts=0x118e8f0, rdispls=0x118e910, datatype=dtype=0x4c000840, comm=comm=0xc4000002) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14abca000000, scnts=0x118e410, sdispls=0x118e8b0, dtype=0x4c000840, rbuf=0x14abca200000, rcnts=0x118e8f0, rdispls=0x118e910, datatype=dtype=0x4c000840, comm=comm=0xc4000002) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 23] [job id 5d7e5dbb-a394-468e-a274-18b6df8b6c41] [Tue Jul 25 02:57:45 2023] [x3112c0s19b0n0] - Abort(405871247) (rank 23 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14ef02000000, scnts=0x110d790, sdispls=0x110dcb0, dtype=0x4c000840, rbuf=0x14ef02200000, rcnts=0x110dcf0, rdispls=0x110dd10, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14ef02000000, scnts=0x110d790, sdispls=0x110dcb0, dtype=0x4c000840, rbuf=0x14ef02200000, rcnts=0x110dcf0, rdispls=0x110dd10, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 29] [job id 5d7e5dbb-a394-468e-a274-18b6df8b6c41] [Tue Jul 25 02:57:45 2023] [x3112c0s1b0n0] - Abort(137435791) (rank 29 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14b1ae000000, scnts=0x9fab40, sdispls=0x9def90, dtype=0x4c000840, rbuf=0x14b1ae200000, rcnts=0x9defd0, rdispls=0x9deff0, datatype=dtype=0x4c000840, comm=comm=0xc4000002) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14b1ae000000, scnts=0x9fab40, sdispls=0x9def90, dtype=0x4c000840, rbuf=0x14b1ae200000, rcnts=0x9defd0, rdispls=0x9deff0, datatype=dtype=0x4c000840, comm=comm=0xc4000002) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 7] [job id 5d7e5dbb-a394-468e-a274-18b6df8b6c41] [Tue Jul 25 02:57:45 2023] [x3111c0s7b0n0] - Abort(70326927) (rank 7 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15042c000000, scnts=0xfd55c0, sdispls=0xfd5910, dtype=0x4c000840, rbuf=0x15042c200000, rcnts=0xfd5950, rdispls=0xfd5970, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15042c000000, scnts=0xfd55c0, sdispls=0xfd5910, dtype=0x4c000840, rbuf=0x15042c200000, rcnts=0xfd5950, rdispls=0xfd5970, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 13] [job id 5d7e5dbb-a394-468e-a274-18b6df8b6c41] [Tue Jul 25 02:57:45 2023] [x3112c0s13b0n0] - Abort(741415567) (rank 13 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f1ae000000, scnts=0x897cd0, sdispls=0x85a4e0, dtype=0x4c000840, rbuf=0x14f1ae200000, rcnts=0x85a520, rdispls=0x85a540, datatype=dtype=0x4c000840, comm=comm=0xc4000002) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f1ae000000, scnts=0x897cd0, sdispls=0x85a4e0, dtype=0x4c000840, rbuf=0x14f1ae200000, rcnts=0x85a520, rdispls=0x85a540, datatype=dtype=0x4c000840, comm=comm=0xc4000002) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 28] [job id 5d7e5dbb-a394-468e-a274-18b6df8b6c41] [Tue Jul 25 02:57:45 2023] [x3112c0s1b0n0] - Abort(808524431) (rank 28 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x149cfc000000, scnts=0x24739a0, sdispls=0x2473a00, dtype=0x4c000840, rbuf=0x149cfc200000, rcnts=0x2473ac0, rdispls=0x2473b20, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x149cfc000000, scnts=0x24739a0, sdispls=0x2473a00, dtype=0x4c000840, rbuf=0x149cfc200000, rcnts=0x2473ac0, rdispls=0x2473b20, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
x3112c0s1b0n0.hsn.cm.polaris.alcf.anl.gov: rank 31 exited with code 255
MPICH ERROR [Rank 3] [job id 5d7e5dbb-a394-468e-a274-18b6df8b6c41] [Tue Jul 25 02:57:45 2023] [x3111c0s37b1n0] - Abort(808524431) (rank 3 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x151558000000, scnts=0x1ebae90, sdispls=0x1ea8210, dtype=0x4c000840, rbuf=0x151558210000, rcnts=0x1ea82d0, rdispls=0x1ea8330, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x151558000000, scnts=0x1ebae90, sdispls=0x1ea8210, dtype=0x4c000840, rbuf=0x151558210000, rcnts=0x1ea82d0, rdispls=0x1ea8330, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 30] [job id 5d7e5dbb-a394-468e-a274-18b6df8b6c41] [Tue Jul 25 02:57:45 2023] [x3112c0s1b0n0] - Abort(607197839) (rank 30 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f1d6000000, scnts=0x7d3f90, sdispls=0x794460, dtype=0x4c000840, rbuf=0x14f1d6200000, rcnts=0x794520, rdispls=0x794580, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f1d6000000, scnts=0x7d3f90, sdispls=0x794460, dtype=0x4c000840, rbuf=0x14f1d6200000, rcnts=0x794520, rdispls=0x794580, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 25] [job id 5d7e5dbb-a394-468e-a274-18b6df8b6c41] [Tue Jul 25 02:57:45 2023] [x3112c0s19b1n0] - Abort(808524431) (rank 25 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f632000000, scnts=0x151ff90, sdispls=0x151d700, dtype=0x4c000840, rbuf=0x14f632200000, rcnts=0x151d7c0, rdispls=0x151d820, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f632000000, scnts=0x151ff90, sdispls=0x151d700, dtype=0x4c000840, rbuf=0x14f632200000, rcnts=0x151d7c0, rdispls=0x151d820, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 20] [job id 5d7e5dbb-a394-468e-a274-18b6df8b6c41] [Tue Jul 25 02:57:45 2023] [x3112c0s19b0n0] - Abort(271653519) (rank 20 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1460b4000000, scnts=0x103bf70, sdispls=0x1052a50, dtype=0x4c000840, rbuf=0x1460b4200000, rcnts=0x1052b10, rdispls=0x1052b70, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1460b4000000, scnts=0x103bf70, sdispls=0x1052a50, dtype=0x4c000840, rbuf=0x1460b4200000, rcnts=0x1052b10, rdispls=0x1052b70, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 2] [job id 5d7e5dbb-a394-468e-a274-18b6df8b6c41] [Tue Jul 25 02:57:45 2023] [x3111c0s37b1n0] - Abort(942742159) (rank 2 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147812000000, scnts=0x18cdf70, sdispls=0x18bb750, dtype=0x4c000840, rbuf=0x147812210000, rcnts=0x18bb810, rdispls=0x18bb870, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147812000000, scnts=0x18cdf70, sdispls=0x18bb750, dtype=0x4c000840, rbuf=0x147812210000, rcnts=0x18bb810, rdispls=0x18bb870, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 10] [job id 5d7e5dbb-a394-468e-a274-18b6df8b6c41] [Tue Jul 25 02:57:45 2023] [x3111c0s7b1n0] - Abort(875633295) (rank 10 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f93a000000, scnts=0x21642b0, sdispls=0x2164aa0, dtype=0x4c000840, rbuf=0x14f93a200000, rcnts=0x2164b60, rdispls=0x2164bc0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f93a000000, scnts=0x21642b0, sdispls=0x2164aa0, dtype=0x4c000840, rbuf=0x14f93a200000, rcnts=0x2164b60, rdispls=0x2164bc0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 6] [job id 5d7e5dbb-a394-468e-a274-18b6df8b6c41] [Tue Jul 25 02:57:45 2023] [x3111c0s7b0n0] - Abort(271653519) (rank 6 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14835a000000, scnts=0x25c4f90, sdispls=0x25a59d0, dtype=0x4c000840, rbuf=0x14835a200000, rcnts=0x25a5a90, rdispls=0x25a5af0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14835a000000, scnts=0x25c4f90, sdispls=0x25a59d0, dtype=0x4c000840, rbuf=0x14835a200000, rcnts=0x25a5a90, rdispls=0x25a5af0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 22] [job id 5d7e5dbb-a394-468e-a274-18b6df8b6c41] [Tue Jul 25 02:57:45 2023] [x3112c0s19b0n0] - Abort(204544655) (rank 22 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1535aa000000, scnts=0x10c3f90, sdispls=0x10a2fd0, dtype=0x4c000840, rbuf=0x1535aa200000, rcnts=0x10a3090, rdispls=0x10a30f0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1535aa000000, scnts=0x10c3f90, sdispls=0x10a2fd0, dtype=0x4c000840, rbuf=0x1535aa200000, rcnts=0x10a3090, rdispls=0x10a30f0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 26] [job id 5d7e5dbb-a394-468e-a274-18b6df8b6c41] [Tue Jul 25 02:57:45 2023] [x3112c0s19b1n0] - Abort(204544655) (rank 26 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14de62000000, scnts=0x22c4300, sdispls=0x22c4b40, dtype=0x4c000840, rbuf=0x14de62200000, rcnts=0x22c4c00, rdispls=0x22c4c60, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14de62000000, scnts=0x22c4300, sdispls=0x22c4b40, dtype=0x4c000840, rbuf=0x14de62200000, rcnts=0x22c4c00, rdispls=0x22c4c60, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 24] [job id 5d7e5dbb-a394-468e-a274-18b6df8b6c41] [Tue Jul 25 02:57:45 2023] [x3112c0s19b1n0] - Abort(942742159) (rank 24 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x149e8c000000, scnts=0x8aaf70, sdispls=0x8c1ab0, dtype=0x4c000840, rbuf=0x149e8c200000, rcnts=0x8c1b70, rdispls=0x8c1bd0, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x149e8c000000, scnts=0x8aaf70, sdispls=0x8c1ab0, dtype=0x4c000840, rbuf=0x149e8c200000, rcnts=0x8c1b70, rdispls=0x8c1bd0, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
