“RANK= 13 LOCAL_RANK= 1 gpu= 2”
“RANK= 12 LOCAL_RANK= 0 gpu= 3”
“RANK= 14 LOCAL_RANK= 2 gpu= 1”
“RANK= 15 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
“RANK= 1 LOCAL_RANK= 1 gpu= 2”
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
“RANK= 2 LOCAL_RANK= 2 gpu= 1”
Shell debugging restarted
“RANK= 3 LOCAL_RANK= 3 gpu= 0”
+ unset __lmod_vx
“RANK= 0 LOCAL_RANK= 0 gpu= 3”
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
“RANK= 24 LOCAL_RANK= 0 gpu= 3”
“RANK= 25 LOCAL_RANK= 1 gpu= 2”
“RANK= 26 LOCAL_RANK= 2 gpu= 1”
“RANK= 27 LOCAL_RANK= 3 gpu= 0”
“RANK= 21 LOCAL_RANK= 1 gpu= 2”
“RANK= 22 LOCAL_RANK= 2 gpu= 1”
“RANK= 23 LOCAL_RANK= 3 gpu= 0”
“RANK= 20 LOCAL_RANK= 0 gpu= 3”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ '[' -z '' ']'
+ case "$-" in
“RANK= 6 LOCAL_RANK= 2 gpu= 1”
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
“RANK= 4 LOCAL_RANK= 0 gpu= 3”
+ set +x
+ '[' -z '' ']'
+ case "$-" in
“RANK= 7 LOCAL_RANK= 3 gpu= 0”
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
“RANK= 5 LOCAL_RANK= 1 gpu= 2”
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ '[' -z '' ']'
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ set +x
+ '[' -z '' ']'
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
Shell debugging restarted
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
“RANK= 16 LOCAL_RANK= 0 gpu= 3”
“RANK= 17 LOCAL_RANK= 1 gpu= 2”
“RANK= 18 LOCAL_RANK= 2 gpu= 1”
“RANK= 19 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
“RANK= 28 LOCAL_RANK= 0 gpu= 3”
“RANK= 29 LOCAL_RANK= 1 gpu= 2”
“RANK= 30 LOCAL_RANK= 2 gpu= 1”
“RANK= 31 LOCAL_RANK= 3 gpu= 0”
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ '[' -z '' ']'
+ case "$-" in
+ '[' -z '' ']'
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
“RANK= 8 LOCAL_RANK= 0 gpu= 3”
“RANK= 9 LOCAL_RANK= 1 gpu= 2”
“RANK= 10 LOCAL_RANK= 2 gpu= 1”
“RANK= 11 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
+ '[' -z '' ']'
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 4 4 2 -n5
MPICH ERROR [Rank 15] [job id 63a2bd1c-c4b6-49d7-95cf-265698d4e2eb] [Fri Aug  4 06:10:39 2023] [x3108c0s7b0n0] - Abort(472980111) (rank 15 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x151dee000000, scnts=0xa93ff0, sdispls=0xa72670, dtype=0x4c000840, rbuf=0x151dee200000, rcnts=0xa726b0, rdispls=0xa726d0, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x151dee000000, scnts=0xa93ff0, sdispls=0xa72670, dtype=0x4c000840, rbuf=0x151dee200000, rcnts=0xa726b0, rdispls=0xa726d0, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 31] [job id 63a2bd1c-c4b6-49d7-95cf-265698d4e2eb] [Fri Aug  4 06:10:39 2023] [x3111c0s25b0n0] - Abort(674306703) (rank 31 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150dba000000, scnts=0x2732e70, sdispls=0x26f2670, dtype=0x4c000840, rbuf=0x150dba200000, rcnts=0x26f26b0, rdispls=0x26f26d0, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150dba000000, scnts=0x2732e70, sdispls=0x26f2670, dtype=0x4c000840, rbuf=0x150dba200000, rcnts=0x26f26b0, rdispls=0x26f26d0, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 21] [job id 63a2bd1c-c4b6-49d7-95cf-265698d4e2eb] [Fri Aug  4 06:10:39 2023] [x3111c0s1b0n0] - Abort(540088975) (rank 21 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14b1da000000, scnts=0x137fef0, sdispls=0x1342670, dtype=0x4c000840, rbuf=0x14b1da200000, rcnts=0x13426b0, rdispls=0x13426d0, datatype=dtype=0x4c000840, comm=comm=0xc4000002) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14b1da000000, scnts=0x137fef0, sdispls=0x1342670, dtype=0x4c000840, rbuf=0x14b1da200000, rcnts=0x13426b0, rdispls=0x13426d0, datatype=dtype=0x4c000840, comm=comm=0xc4000002) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 29] [job id 63a2bd1c-c4b6-49d7-95cf-265698d4e2eb] [Fri Aug  4 06:10:39 2023] [x3111c0s25b0n0] - Abort(70326927) (rank 29 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150b84000000, scnts=0x20cbb40, sdispls=0x20cdfd0, dtype=0x4c000840, rbuf=0x150b84200000, rcnts=0x2095fc0, rdispls=0x2095fe0, datatype=dtype=0x4c000840, comm=comm=0xc4000002) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150b84000000, scnts=0x20cbb40, sdispls=0x20cdfd0, dtype=0x4c000840, rbuf=0x150b84200000, rcnts=0x2095fc0, rdispls=0x2095fe0, datatype=dtype=0x4c000840, comm=comm=0xc4000002) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 7] [job id 63a2bd1c-c4b6-49d7-95cf-265698d4e2eb] [Fri Aug  4 06:10:39 2023] [x3108c0s37b0n0] - Abort(204544655) (rank 7 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14c2cc000000, scnts=0x1840750, sdispls=0x1840c30, dtype=0x4c000840, rbuf=0x14c2cc200000, rcnts=0x1840c70, rdispls=0x1840c90, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14c2cc000000, scnts=0x1840750, sdispls=0x1840c30, dtype=0x4c000840, rbuf=0x14c2cc200000, rcnts=0x1840c70, rdispls=0x1840c90, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 23] [job id 63a2bd1c-c4b6-49d7-95cf-265698d4e2eb] [Fri Aug  4 06:10:39 2023] [x3111c0s1b0n0] - Abort(674306703) (rank 23 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15524e000000, scnts=0x109ac20, sdispls=0x105d4e0, dtype=0x4c000840, rbuf=0x15524e200000, rcnts=0x105d520, rdispls=0x105d540, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15524e000000, scnts=0x109ac20, sdispls=0x105d4e0, dtype=0x4c000840, rbuf=0x15524e200000, rcnts=0x105d520, rdispls=0x105d540, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 17] [job id 63a2bd1c-c4b6-49d7-95cf-265698d4e2eb] [Fri Aug  4 06:10:40 2023] [x3108c0s7b1n0] - Abort(338762383) (rank 17 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150db4000000, scnts=0x18c2b60, sdispls=0x18c3000, dtype=0x4c000840, rbuf=0x150db4210000, rcnts=0x18c3040, rdispls=0x18c3060, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150db4000000, scnts=0x18c2b60, sdispls=0x18c3000, dtype=0x4c000840, rbuf=0x150db4210000, rcnts=0x18c3040, rdispls=0x18c3060, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 16] [job id 63a2bd1c-c4b6-49d7-95cf-265698d4e2eb] [Fri Aug  4 06:10:40 2023] [x3108c0s7b1n0] - Abort(472980111) (rank 16 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x148ec2000000, scnts=0xc2a610, sdispls=0xc2aab0, dtype=0x4c000840, rbuf=0x148ec2210000, rcnts=0xc2aaf0, rdispls=0xc2ab10, datatype=dtype=0x4c000840, comm=comm=0xc4000009) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x148ec2000000, scnts=0xc2a610, sdispls=0xc2aab0, dtype=0x4c000840, rbuf=0x148ec2210000, rcnts=0xc2aaf0, rdispls=0xc2ab10, datatype=dtype=0x4c000840, comm=comm=0xc4000009) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 28] [job id 63a2bd1c-c4b6-49d7-95cf-265698d4e2eb] [Fri Aug  4 06:10:40 2023] [x3111c0s25b0n0] - Abort(875633295) (rank 28 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1544d4000000, scnts=0x1112460, sdispls=0x11124c0, dtype=0x4c000840, rbuf=0x1544d4200000, rcnts=0x1112580, rdispls=0x11125e0, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1544d4000000, scnts=0x1112460, sdispls=0x11124c0, dtype=0x4c000840, rbuf=0x1544d4200000, rcnts=0x1112580, rdispls=0x11125e0, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
x3108c0s7b0n0.hsn.cm.polaris.alcf.anl.gov: rank 15 exited with code 255
MPICH ERROR [Rank 30] [job id 63a2bd1c-c4b6-49d7-95cf-265698d4e2eb] [Fri Aug  4 06:10:40 2023] [x3111c0s25b0n0] - Abort(3218063) (rank 30 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14752a000000, scnts=0x1150f90, sdispls=0x112f9d0, dtype=0x4c000840, rbuf=0x14752a200000, rcnts=0x112fa90, rdispls=0x112faf0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14752a000000, scnts=0x1150f90, sdispls=0x112f9d0, dtype=0x4c000840, rbuf=0x14752a200000, rcnts=0x112fa90, rdispls=0x112faf0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 3] [job id 63a2bd1c-c4b6-49d7-95cf-265698d4e2eb] [Fri Aug  4 06:10:40 2023] [x3108c0s31b1n0] - Abort(405871247) (rank 3 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x152522000000, scnts=0xf62f70, sdispls=0xf26420, dtype=0x4c000840, rbuf=0x152522210000, rcnts=0xf264e0, rdispls=0xf26540, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x152522000000, scnts=0xf62f70, sdispls=0xf26420, dtype=0x4c000840, rbuf=0x152522210000, rcnts=0xf264e0, rdispls=0xf26540, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 10] [job id 63a2bd1c-c4b6-49d7-95cf-265698d4e2eb] [Fri Aug  4 06:10:40 2023] [x3108c0s37b1n0] - Abort(271653519) (rank 10 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14d564000000, scnts=0x1738d00, sdispls=0x16fb860, dtype=0x4c000840, rbuf=0x14d564200000, rcnts=0x16fb920, rdispls=0x16fb980, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14d564000000, scnts=0x1738d00, sdispls=0x16fb860, dtype=0x4c000840, rbuf=0x14d564200000, rcnts=0x16fb920, rdispls=0x16fb980, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 20] [job id 63a2bd1c-c4b6-49d7-95cf-265698d4e2eb] [Fri Aug  4 06:10:40 2023] [x3111c0s1b0n0] - Abort(674306703) (rank 20 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x145ef2000000, scnts=0x22fbf90, sdispls=0x2332460, dtype=0x4c000840, rbuf=0x145ef2200000, rcnts=0x2332520, rdispls=0x2332580, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x145ef2000000, scnts=0x22fbf90, sdispls=0x2332460, dtype=0x4c000840, rbuf=0x145ef2200000, rcnts=0x2332520, rdispls=0x2332580, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 2] [job id 63a2bd1c-c4b6-49d7-95cf-265698d4e2eb] [Fri Aug  4 06:10:40 2023] [x3108c0s31b1n0] - Abort(741415567) (rank 2 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14607e000000, scnts=0x173ef30, sdispls=0x173fa00, dtype=0x4c000840, rbuf=0x14607e210000, rcnts=0x173fac0, rdispls=0x173fb20, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14607e000000, scnts=0x173ef30, sdispls=0x173fa00, dtype=0x4c000840, rbuf=0x14607e210000, rcnts=0x173fac0, rdispls=0x173fb20, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 8] [job id 63a2bd1c-c4b6-49d7-95cf-265698d4e2eb] [Fri Aug  4 06:10:40 2023] [x3108c0s37b1n0] - Abort(472455695) (rank 8 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389).........: MPI_Alltoallv(sbuf=0x14a26e000000, scnts=0x1440f90, sdispls=0x14756b0, dtype=0x4c000840, rbuf=0x14a26e200000, rcnts=0x1475770, rdispls=0x14757d0, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1155)...: 
MPIC_Isend(511).............: 
MPID_Isend_coll(610)........: 
MPIDI_isend_coll_unsafe(176): 
MPIDI_OFI_send_normal(352)..: OFI tagged senddata failed (ofi_send.h:352:MPIDI_OFI_send_normal:No route to host)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389).........: MPI_Alltoallv(sbuf=0x14a26e000000, scnts=0x1440f90, sdispls=0x14756b0, dtype=0x4c000840, rbuf=0x14a26e200000, rcnts=0x1475770, rdispls=0x14757d0, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1155)...: 
MPIC_Isend(511).............: 
MPID_Isend_coll(610)........: 
MPIDI_isend_coll_unsafe(176): 
MPIDI_OFI_send_normal(352)..: OFI tagged senddata failed (ofi_send.h:352:MPIDI_OFI_send_normal:No route to host)
MPICH ERROR [Rank 25] [job id 63a2bd1c-c4b6-49d7-95cf-265698d4e2eb] [Fri Aug  4 06:10:40 2023] [x3111c0s1b1n0] - Abort(875633295) (rank 25 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1500ae000000, scnts=0x2679f70, sdispls=0x263d270, dtype=0x4c000840, rbuf=0x1500ae200000, rcnts=0x263d330, rdispls=0x263d390, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1500ae000000, scnts=0x2679f70, sdispls=0x263d270, dtype=0x4c000840, rbuf=0x1500ae200000, rcnts=0x263d330, rdispls=0x263d390, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 22] [job id 63a2bd1c-c4b6-49d7-95cf-265698d4e2eb] [Fri Aug  4 06:10:40 2023] [x3111c0s1b0n0] - Abort(741415567) (rank 22 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1473a4000000, scnts=0x1d49f90, sdispls=0x1d2a840, dtype=0x4c000840, rbuf=0x1473a4200000, rcnts=0x1d2a900, rdispls=0x1d2a960, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1473a4000000, scnts=0x1d49f90, sdispls=0x1d2a840, dtype=0x4c000840, rbuf=0x1473a4200000, rcnts=0x1d2a900, rdispls=0x1d2a960, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 26] [job id 63a2bd1c-c4b6-49d7-95cf-265698d4e2eb] [Fri Aug  4 06:10:40 2023] [x3111c0s1b1n0] - Abort(741415567) (rank 26 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14e724000000, scnts=0x1ad5d80, sdispls=0x1ad5de0, dtype=0x4c000840, rbuf=0x14e724200000, rcnts=0x1a95210, rdispls=0x1a95270, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14e724000000, scnts=0x1ad5d80, sdispls=0x1ad5de0, dtype=0x4c000840, rbuf=0x14e724200000, rcnts=0x1a95210, rdispls=0x1a95270, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 6] [job id 63a2bd1c-c4b6-49d7-95cf-265698d4e2eb] [Fri Aug  4 06:10:40 2023] [x3108c0s37b0n0] - Abort(1009851023) (rank 6 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14a774000000, scnts=0x23fd630, sdispls=0x23fde70, dtype=0x4c000840, rbuf=0x14a774200000, rcnts=0x23fdf30, rdispls=0x23fdf90, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14a774000000, scnts=0x23fd630, sdispls=0x23fde70, dtype=0x4c000840, rbuf=0x14a774200000, rcnts=0x23fdf30, rdispls=0x23fdf90, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 24] [job id 63a2bd1c-c4b6-49d7-95cf-265698d4e2eb] [Fri Aug  4 06:10:40 2023] [x3111c0s1b1n0] - Abort(942742159) (rank 24 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1476fa000000, scnts=0x2620f30, sdispls=0x2659ab0, dtype=0x4c000840, rbuf=0x1476fa200000, rcnts=0x2659b70, rdispls=0x2659bd0, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1476fa000000, scnts=0x2620f30, sdispls=0x2659ab0, dtype=0x4c000840, rbuf=0x1476fa200000, rcnts=0x2659b70, rdispls=0x2659bd0, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
