“RANK= 0 LOCAL_RANK= 0 gpu= 3”
“RANK= 1 LOCAL_RANK= 1 gpu= 2”
“RANK= 2 LOCAL_RANK= 2 gpu= 1”
“RANK= 3 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 4 2 1
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 4 2 1
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 4 2 1
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 4 2 1
“RANK= 4 LOCAL_RANK= 0 gpu= 3”
“RANK= 5 LOCAL_RANK= 1 gpu= 2”
“RANK= 6 LOCAL_RANK= 2 gpu= 1”
“RANK= 7 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 4 2 1
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 4 2 1
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 4 2 1
+ speed3d_r2c cufft float 256 256 256 -no-reorder -r2c_dir 1 -ingrid 4 2 1
MPICH ERROR [Rank 3] [job id 2f54184a-a040-40a3-93c2-b6d8b359ece6] [Sat Jul  1 22:40:49 2023] [x3010c0s37b0n0] - Abort(808524431) (rank 3 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1474a4000000, scnts=0x262ded0, sdispls=0x262e1e0, dtype=0x4c000840, rbuf=0x1474a4800000, rcnts=0x262e220, rdispls=0x262e3d0, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1474a4000000, scnts=0x262ded0, sdispls=0x262e1e0, dtype=0x4c000840, rbuf=0x1474a4800000, rcnts=0x262e220, rdispls=0x262e3d0, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 7] [job id 2f54184a-a040-40a3-93c2-b6d8b359ece6] [Sat Jul  1 22:40:49 2023] [x3010c0s37b1n0] - Abort(540088975) (rank 7 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14b8c6000000, scnts=0x2207ef0, sdispls=0x2208200, dtype=0x4c000840, rbuf=0x14b8c6800000, rcnts=0x2208240, rdispls=0x22083f0, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14b8c6000000, scnts=0x2207ef0, sdispls=0x2208200, dtype=0x4c000840, rbuf=0x14b8c6800000, rcnts=0x2208240, rdispls=0x22083f0, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 2] [job id 2f54184a-a040-40a3-93c2-b6d8b359ece6] [Sat Jul  1 22:40:49 2023] [x3010c0s37b0n0] - Abort(405871247) (rank 2 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14c814000000, scnts=0x162d1a0, sdispls=0x162d4b0, dtype=0x4c000840, rbuf=0x14c814800000, rcnts=0x162d4f0, rdispls=0x162d6a0, datatype=dtype=0x4c000840, comm=comm=0xc4000006) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

MPICH ERROR [Rank 6] [job id 2f54184a-a040-40a3-93c2-b6d8b359ece6] [Sat Jul  1 22:40:49 2023] [x3010c0s37b1n0] - Abort(338762383) (rank 6 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15073e000000, scnts=0x1c99470, sdispls=0x1c99780, dtype=0x4c000840, rbuf=0x15073e800000, rcnts=0x1c997c0, rdispls=0x1c99970, datatype=dtype=0x4c000840, comm=comm=0xc4000006) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14c814000000, scnts=0x162d1a0, sdispls=0x162d4b0, dtype=0x4c000840, rbuf=0x14c814800000, rcnts=0x162d4f0, rdispls=0x162d6a0, datatype=dtype=0x4c000840, comm=comm=0xc4000006) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15073e000000, scnts=0x1c99470, sdispls=0x1c99780, dtype=0x4c000840, rbuf=0x15073e800000, rcnts=0x1c997c0, rdispls=0x1c99970, datatype=dtype=0x4c000840, comm=comm=0xc4000006) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 4] [job id 2f54184a-a040-40a3-93c2-b6d8b359ece6] [Sat Jul  1 22:40:49 2023] [x3010c0s37b1n0] - Abort(741415567) (rank 4 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14cc9e000000, scnts=0x140ceb0, sdispls=0x140d1c0, dtype=0x4c000840, rbuf=0x14cc9e820000, rcnts=0x140d200, rdispls=0x140d3b0, datatype=dtype=0x4c000840, comm=comm=0xc4000009) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14cc9e000000, scnts=0x140ceb0, sdispls=0x140d1c0, dtype=0x4c000840, rbuf=0x14cc9e820000, rcnts=0x140d200, rdispls=0x140d3b0, datatype=dtype=0x4c000840, comm=comm=0xc4000009) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 5] [job id 2f54184a-a040-40a3-93c2-b6d8b359ece6] [Sat Jul  1 22:40:49 2023] [x3010c0s37b1n0] - Abort(70326927) (rank 5 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x149636000000, scnts=0x2163620, sdispls=0x2163930, dtype=0x4c000840, rbuf=0x149636820000, rcnts=0x2163970, rdispls=0x2163b20, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x149636000000, scnts=0x2163620, sdispls=0x2163930, dtype=0x4c000840, rbuf=0x149636820000, rcnts=0x2163970, rdispls=0x2163b20, datatype=dtype=0x4c000840, comm=comm=0xc4000004) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
x3010c0s37b0n0.hsn.cm.polaris.alcf.anl.gov: rank 3 exited with code 255
