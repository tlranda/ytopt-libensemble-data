“RANK= 3 LOCAL_RANK= 3 gpu= 0”
“RANK= 1 LOCAL_RANK= 1 gpu= 2”
“RANK= 2 LOCAL_RANK= 2 gpu= 1”
“RANK= 0 LOCAL_RANK= 0 gpu= 3”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 512 -reorder -a2av -r2c_dir 2 -ingrid 8 2 1 -outgrid 16 1 1 -n5
+ speed3d_r2c cufft float 256 256 512 -reorder -a2av -r2c_dir 2 -ingrid 8 2 1 -outgrid 16 1 1 -n5
+ speed3d_r2c cufft float 256 256 512 -reorder -a2av -r2c_dir 2 -ingrid 8 2 1 -outgrid 16 1 1 -n5
+ speed3d_r2c cufft float 256 256 512 -reorder -a2av -r2c_dir 2 -ingrid 8 2 1 -outgrid 16 1 1 -n5
“RANK= 8 LOCAL_RANK= 0 gpu= 3”
“RANK= 11 LOCAL_RANK= 3 gpu= 0”
“RANK= 10 LOCAL_RANK= 2 gpu= 1”
“RANK= 9 LOCAL_RANK= 1 gpu= 2”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 512 -reorder -a2av -r2c_dir 2 -ingrid 8 2 1 -outgrid 16 1 1 -n5
+ speed3d_r2c cufft float 256 256 512 -reorder -a2av -r2c_dir 2 -ingrid 8 2 1 -outgrid 16 1 1 -n5
+ speed3d_r2c cufft float 256 256 512 -reorder -a2av -r2c_dir 2 -ingrid 8 2 1 -outgrid 16 1 1 -n5
+ speed3d_r2c cufft float 256 256 512 -reorder -a2av -r2c_dir 2 -ingrid 8 2 1 -outgrid 16 1 1 -n5
“RANK= 15 LOCAL_RANK= 3 gpu= 0”
“RANK= 12 LOCAL_RANK= 0 gpu= 3”
“RANK= 14 LOCAL_RANK= 2 gpu= 1”
“RANK= 13 LOCAL_RANK= 1 gpu= 2”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
“RANK= 4 LOCAL_RANK= 0 gpu= 3”
+ '[' -n x ']'
+ set +x
“RANK= 6 LOCAL_RANK= 2 gpu= 1”
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
“RANK= 5 LOCAL_RANK= 1 gpu= 2”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
“RANK= 7 LOCAL_RANK= 3 gpu= 0”
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 512 -reorder -a2av -r2c_dir 2 -ingrid 8 2 1 -outgrid 16 1 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 512 -reorder -a2av -r2c_dir 2 -ingrid 8 2 1 -outgrid 16 1 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 512 -reorder -a2av -r2c_dir 2 -ingrid 8 2 1 -outgrid 16 1 1 -n5
+ speed3d_r2c cufft float 256 256 512 -reorder -a2av -r2c_dir 2 -ingrid 8 2 1 -outgrid 16 1 1 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 512 -reorder -a2av -r2c_dir 2 -ingrid 8 2 1 -outgrid 16 1 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 512 -reorder -a2av -r2c_dir 2 -ingrid 8 2 1 -outgrid 16 1 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 512 -reorder -a2av -r2c_dir 2 -ingrid 8 2 1 -outgrid 16 1 1 -n5
+ speed3d_r2c cufft float 256 256 512 -reorder -a2av -r2c_dir 2 -ingrid 8 2 1 -outgrid 16 1 1 -n5
MPICH ERROR [Rank 9] [job id dee5618e-f8a6-4f57-b8a0-3b9068f258fa] [Sun Nov 12 08:39:23 2023] [x3204c0s19b0n0] - Abort(338762383) (rank 9 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14b0a4000000, scnts=0x924770, sdispls=0x924f30, dtype=0x4c000840, rbuf=0x14b0a4808000, rcnts=0x924fd0, rdispls=0x925020, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14b0a4000000, scnts=0x924770, sdispls=0x924f30, dtype=0x4c000840, rbuf=0x14b0a4808000, rcnts=0x924fd0, rdispls=0x925020, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 15] [job id dee5618e-f8a6-4f57-b8a0-3b9068f258fa] [Sun Nov 12 08:39:23 2023] [x3204c0s19b1n0] - Abort(674306703) (rank 15 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1477a6000000, scnts=0xbadd20, sdispls=0xbc87a0, dtype=0x4c000840, rbuf=0x1477a6808000, rcnts=0xbc8840, rdispls=0xbc8890, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1477a6000000, scnts=0xbadd20, sdispls=0xbc87a0, dtype=0x4c000840, rbuf=0x1477a6808000, rcnts=0xbc8840, rdispls=0xbc8890, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 13] [job id dee5618e-f8a6-4f57-b8a0-3b9068f258fa] [Sun Nov 12 08:39:23 2023] [x3204c0s19b1n0] - Abort(137435791) (rank 13 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14d106000000, scnts=0x1dded20, sdispls=0x1df97a0, dtype=0x4c000840, rbuf=0x14d106808000, rcnts=0x1df9840, rdispls=0x1df9890, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14d106000000, scnts=0x1dded20, sdispls=0x1df97a0, dtype=0x4c000840, rbuf=0x14d106808000, rcnts=0x1df9840, rdispls=0x1df9890, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 7] [job id dee5618e-f8a6-4f57-b8a0-3b9068f258fa] [Sun Nov 12 08:39:23 2023] [x3204c0s13b1n0] - Abort(472980111) (rank 7 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x153ece000000, scnts=0x80fd50, sdispls=0x8487f0, dtype=0x4c000840, rbuf=0x153ece808000, rcnts=0x848890, rdispls=0x8488e0, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x153ece000000, scnts=0x80fd50, sdispls=0x8487f0, dtype=0x4c000840, rbuf=0x153ece808000, rcnts=0x848890, rdispls=0x8488e0, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 11] [job id dee5618e-f8a6-4f57-b8a0-3b9068f258fa] [Sun Nov 12 08:39:23 2023] [x3204c0s19b0n0] - Abort(204544655) (rank 11 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14bb56000000, scnts=0x24dc590, sdispls=0x24dcd50, dtype=0x4c000840, rbuf=0x14bb56808000, rcnts=0x24dcdf0, rdispls=0x24dce40, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14bb56000000, scnts=0x24dc590, sdispls=0x24dcd50, dtype=0x4c000840, rbuf=0x14bb56808000, rcnts=0x24dcdf0, rdispls=0x24dce40, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 6] [job id dee5618e-f8a6-4f57-b8a0-3b9068f258fa] [Sun Nov 12 08:39:23 2023] [x3204c0s13b1n0] - Abort(942742159) (rank 6 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x148c8e000000, scnts=0x127dc60, sdispls=0x12b6660, dtype=0x4c000840, rbuf=0x148c8e808000, rcnts=0x12b6700, rdispls=0x12b6750, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x148c8e000000, scnts=0x127dc60, sdispls=0x12b6660, dtype=0x4c000840, rbuf=0x148c8e808000, rcnts=0x12b6700, rdispls=0x12b6750, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 8] [job id dee5618e-f8a6-4f57-b8a0-3b9068f258fa] [Sun Nov 12 08:39:23 2023] [x3204c0s19b0n0] - Abort(540088975) (rank 8 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14c9e6000000, scnts=0x238abf0, sdispls=0x232f940, dtype=0x4c000840, rbuf=0x14c9e6808000, rcnts=0x232f9e0, rdispls=0x232fa30, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14c9e6000000, scnts=0x238abf0, sdispls=0x232f940, dtype=0x4c000840, rbuf=0x14c9e6808000, rcnts=0x232f9e0, rdispls=0x232fa30, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 2] [job id dee5618e-f8a6-4f57-b8a0-3b9068f258fa] [Sun Nov 12 08:39:23 2023] [x3204c0s13b0n0] - Abort(405871247) (rank 2 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147d56000000, scnts=0x2328710, sdispls=0x2328ed0, dtype=0x4c000840, rbuf=0x147d56808000, rcnts=0x2328f70, rdispls=0x2328fc0, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147d56000000, scnts=0x2328710, sdispls=0x2328ed0, dtype=0x4c000840, rbuf=0x147d56808000, rcnts=0x2328f70, rdispls=0x2328fc0, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 14] [job id dee5618e-f8a6-4f57-b8a0-3b9068f258fa] [Sun Nov 12 08:39:23 2023] [x3204c0s19b1n0] - Abort(338762383) (rank 14 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1495d6000000, scnts=0x137acd0, sdispls=0x1395750, dtype=0x4c000840, rbuf=0x1495d6808000, rcnts=0x13957f0, rdispls=0x1395840, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1495d6000000, scnts=0x137acd0, sdispls=0x1395750, dtype=0x4c000840, rbuf=0x1495d6808000, rcnts=0x13957f0, rdispls=0x1395840, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 3] [job id dee5618e-f8a6-4f57-b8a0-3b9068f258fa] [Sun Nov 12 08:39:23 2023] [x3204c0s13b0n0] - Abort(540088975) (rank 3 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14e516000000, scnts=0x22ae710, sdispls=0x22aeed0, dtype=0x4c000840, rbuf=0x14e516808000, rcnts=0x22aef70, rdispls=0x22aefc0, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14e516000000, scnts=0x22ae710, sdispls=0x22aeed0, dtype=0x4c000840, rbuf=0x14e516808000, rcnts=0x22aef70, rdispls=0x22aefc0, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 0] [job id dee5618e-f8a6-4f57-b8a0-3b9068f258fa] [Sun Nov 12 08:39:23 2023] [x3204c0s13b0n0] - Abort(741415567) (rank 0 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x155296000000, scnts=0x1312e00, sdispls=0x134fcd0, dtype=0x4c000840, rbuf=0x155296808000, rcnts=0x134fd70, rdispls=0x134fdc0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x155296000000, scnts=0x1312e00, sdispls=0x134fcd0, dtype=0x4c000840, rbuf=0x155296808000, rcnts=0x134fd70, rdispls=0x134fdc0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 1] [job id dee5618e-f8a6-4f57-b8a0-3b9068f258fa] [Sun Nov 12 08:39:23 2023] [x3204c0s13b0n0] - Abort(808524431) (rank 1 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14ce54000000, scnts=0x1f17710, sdispls=0x1f17ed0, dtype=0x4c000840, rbuf=0x14ce54808000, rcnts=0x1f17f70, rdispls=0x1f17fc0, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

MPICH ERROR [Rank 4] [job id dee5618e-f8a6-4f57-b8a0-3b9068f258fa] [Sun Nov 12 08:39:23 2023] [x3204c0s13b1n0] - Abort(875633295) (rank 4 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154754000000, scnts=0xa0b030, sdispls=0xa0ba80, dtype=0x4c000840, rbuf=0x154754808000, rcnts=0xa0bb20, rdispls=0xa0bb70, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154754000000, scnts=0xa0b030, sdispls=0xa0ba80, dtype=0x4c000840, rbuf=0x154754808000, rcnts=0xa0bb20, rdispls=0xa0bb70, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14ce54000000, scnts=0x1f17710, sdispls=0x1f17ed0, dtype=0x4c000840, rbuf=0x14ce54808000, rcnts=0x1f17f70, rdispls=0x1f17fc0, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 12] [job id dee5618e-f8a6-4f57-b8a0-3b9068f258fa] [Sun Nov 12 08:39:23 2023] [x3204c0s19b1n0] - Abort(472980111) (rank 12 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x151ac6000000, scnts=0xc810d0, sdispls=0xc81b20, dtype=0x4c000840, rbuf=0x151ac6808000, rcnts=0xc81bc0, rdispls=0xc81c10, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x151ac6000000, scnts=0xc810d0, sdispls=0xc81b20, dtype=0x4c000840, rbuf=0x151ac6808000, rcnts=0xc81bc0, rdispls=0xc81c10, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 5] [job id dee5618e-f8a6-4f57-b8a0-3b9068f258fa] [Sun Nov 12 08:39:23 2023] [x3204c0s13b1n0] - Abort(472980111) (rank 5 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14d80e000000, scnts=0xb90390, sdispls=0xb90b50, dtype=0x4c000840, rbuf=0x14d80e808000, rcnts=0xb90bf0, rdispls=0xb90c40, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14d80e000000, scnts=0xb90390, sdispls=0xb90b50, dtype=0x4c000840, rbuf=0x14d80e808000, rcnts=0xb90bf0, rdispls=0xb90c40, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 10] [job id dee5618e-f8a6-4f57-b8a0-3b9068f258fa] [Sun Nov 12 08:39:23 2023] [x3204c0s19b0n0] - Abort(1009851023) (rank 10 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f2be000000, scnts=0x18c1b80, sdispls=0x18dda40, dtype=0x4c000840, rbuf=0x14f2be808000, rcnts=0x18ddae0, rdispls=0x18ddb30, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f2be000000, scnts=0x18c1b80, sdispls=0x18dda40, dtype=0x4c000840, rbuf=0x14f2be808000, rcnts=0x18ddae0, rdispls=0x18ddb30, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
x3204c0s19b1n0.hsn.cm.polaris.alcf.anl.gov: rank 15 exited with code 255
