“RANK= 0 LOCAL_RANK= 0 gpu= 3”
“RANK= 1 LOCAL_RANK= 1 gpu= 2”
“RANK= 3 LOCAL_RANK= 3 gpu= 0”
“RANK= 2 LOCAL_RANK= 2 gpu= 1”
“RANK= 8 LOCAL_RANK= 0 gpu= 3”
“RANK= 9 LOCAL_RANK= 1 gpu= 2”
“RANK= 11 LOCAL_RANK= 3 gpu= 0”
“RANK= 10 LOCAL_RANK= 2 gpu= 1”
“RANK= 5 LOCAL_RANK= 1 gpu= 2”
“RANK= 4 LOCAL_RANK= 0 gpu= 3”
“RANK= 6 LOCAL_RANK= 2 gpu= 1”
“RANK= 7 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 4 4 -outgrid 1 2 8 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 4 4 -outgrid 1 2 8 -n5
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 4 4 -outgrid 1 2 8 -n5
+ '[' -z '' ']'
+ case "$-" in
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 4 4 -outgrid 1 2 8 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 4 4 -outgrid 1 2 8 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 4 4 -outgrid 1 2 8 -n5
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 4 4 -outgrid 1 2 8 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 4 4 -outgrid 1 2 8 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 4 4 -outgrid 1 2 8 -n5
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 4 4 -outgrid 1 2 8 -n5
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 4 4 -outgrid 1 2 8 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 4 4 -outgrid 1 2 8 -n5
“RANK= 13 LOCAL_RANK= 1 gpu= 2”
“RANK= 12 LOCAL_RANK= 0 gpu= 3”
“RANK= 15 LOCAL_RANK= 3 gpu= 0”
“RANK= 14 LOCAL_RANK= 2 gpu= 1”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 4 4 -outgrid 1 2 8 -n5
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 4 4 -outgrid 1 2 8 -n5
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 4 4 -outgrid 1 2 8 -n5
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 4 4 -outgrid 1 2 8 -n5
MPICH ERROR [Rank 2] [job id 1298e74b-8ce0-47cd-a7d5-841895e53139] [Sun Nov 12 08:28:57 2023] [x3204c0s13b0n0] - Abort(137435791) (rank 2 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x149cec000000, scnts=0x88c900, sdispls=0x88d0c0, dtype=0x4c000840, rbuf=0x149cec810000, rcnts=0x88d160, rdispls=0x88d1b0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x149cec000000, scnts=0x88c900, sdispls=0x88d0c0, dtype=0x4c000840, rbuf=0x149cec810000, rcnts=0x88d160, rdispls=0x88d1b0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 15] [job id 1298e74b-8ce0-47cd-a7d5-841895e53139] [Sun Nov 12 08:28:57 2023] [x3204c0s19b1n0] - Abort(607197839) (rank 15 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14ccf8000000, scnts=0x22cdb20, sdispls=0x22ce2e0, dtype=0x4c000840, rbuf=0x14ccf8810000, rcnts=0x22ce380, rdispls=0x22ce3d0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14ccf8000000, scnts=0x22cdb20, sdispls=0x22ce2e0, dtype=0x4c000840, rbuf=0x14ccf8810000, rcnts=0x22ce380, rdispls=0x22ce3d0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 5] [job id 1298e74b-8ce0-47cd-a7d5-841895e53139] [Sun Nov 12 08:28:57 2023] [x3204c0s13b1n0] - Abort(338762383) (rank 5 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1533a6000000, scnts=0x2731b20, sdispls=0x27322e0, dtype=0x4c000840, rbuf=0x1533a6810000, rcnts=0x2732380, rdispls=0x27323d0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1533a6000000, scnts=0x2731b20, sdispls=0x27322e0, dtype=0x4c000840, rbuf=0x1533a6810000, rcnts=0x2732380, rdispls=0x27323d0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 0] [job id 1298e74b-8ce0-47cd-a7d5-841895e53139] [Sun Nov 12 08:28:57 2023] [x3204c0s13b0n0] - Abort(405871247) (rank 0 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14ec02000000, scnts=0x1e3e140, sdispls=0x1e3eb90, dtype=0x4c000840, rbuf=0x14ec02810000, rcnts=0x1e3ec30, rdispls=0x1e3ec80, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14ec02000000, scnts=0x1e3e140, sdispls=0x1e3eb90, dtype=0x4c000840, rbuf=0x14ec02810000, rcnts=0x1e3ec30, rdispls=0x1e3ec80, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 6] [job id 1298e74b-8ce0-47cd-a7d5-841895e53139] [Sun Nov 12 08:28:57 2023] [x3204c0s13b1n0] - Abort(405871247) (rank 6 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15417c000000, scnts=0x2719b20, sdispls=0x271a2e0, dtype=0x4c000840, rbuf=0x15417c810000, rcnts=0x271a380, rdispls=0x271a3d0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15417c000000, scnts=0x2719b20, sdispls=0x271a2e0, dtype=0x4c000840, rbuf=0x15417c810000, rcnts=0x271a380, rdispls=0x271a3d0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 7] [job id 1298e74b-8ce0-47cd-a7d5-841895e53139] [Sun Nov 12 08:28:57 2023] [x3204c0s13b1n0] - Abort(472980111) (rank 7 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14641a000000, scnts=0x26efb20, sdispls=0x26f02e0, dtype=0x4c000840, rbuf=0x14641a810000, rcnts=0x26f0380, rdispls=0x26f03d0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14641a000000, scnts=0x26efb20, sdispls=0x26f02e0, dtype=0x4c000840, rbuf=0x14641a810000, rcnts=0x26f0380, rdispls=0x26f03d0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 10] [job id 1298e74b-8ce0-47cd-a7d5-841895e53139] [Sun Nov 12 08:28:57 2023] [x3204c0s19b0n0] - Abort(70326927) (rank 10 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14ff1c000000, scnts=0xe13f00, sdispls=0xe146c0, dtype=0x4c000840, rbuf=0x14ff1c810000, rcnts=0xe14760, rdispls=0xe147b0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14ff1c000000, scnts=0xe13f00, sdispls=0xe146c0, dtype=0x4c000840, rbuf=0x14ff1c810000, rcnts=0xe14760, rdispls=0xe147b0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 1] [job id 1298e74b-8ce0-47cd-a7d5-841895e53139] [Sun Nov 12 08:28:57 2023] [x3204c0s13b0n0] - Abort(942742159) (rank 1 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f3c8000000, scnts=0x2561900, sdispls=0x25620c0, dtype=0x4c000840, rbuf=0x14f3c8810000, rcnts=0x2562160, rdispls=0x25621b0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f3c8000000, scnts=0x2561900, sdispls=0x25620c0, dtype=0x4c000840, rbuf=0x14f3c8810000, rcnts=0x2562160, rdispls=0x25621b0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 12] [job id 1298e74b-8ce0-47cd-a7d5-841895e53139] [Sun Nov 12 08:28:57 2023] [x3204c0s19b1n0] - Abort(808524431) (rank 12 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x145618000000, scnts=0x2508e30, sdispls=0x24adb40, dtype=0x4c000840, rbuf=0x145618810000, rcnts=0x24adbe0, rdispls=0x24adc30, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x145618000000, scnts=0x2508e30, sdispls=0x24adb40, dtype=0x4c000840, rbuf=0x145618810000, rcnts=0x24adbe0, rdispls=0x24adc30, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 13] [job id 1298e74b-8ce0-47cd-a7d5-841895e53139] [Sun Nov 12 08:28:57 2023] [x3204c0s19b1n0] - Abort(70326927) (rank 13 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14649c000000, scnts=0x1582b20, sdispls=0x15832e0, dtype=0x4c000840, rbuf=0x14649c810000, rcnts=0x1583380, rdispls=0x15833d0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14649c000000, scnts=0x1582b20, sdispls=0x15832e0, dtype=0x4c000840, rbuf=0x14649c810000, rcnts=0x1583380, rdispls=0x15833d0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 14] [job id 1298e74b-8ce0-47cd-a7d5-841895e53139] [Sun Nov 12 08:28:57 2023] [x3204c0s19b1n0] - Abort(338762383) (rank 14 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14b8d8000000, scnts=0x2232b20, sdispls=0x22332e0, dtype=0x4c000840, rbuf=0x14b8d8810000, rcnts=0x2233380, rdispls=0x22333d0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14b8d8000000, scnts=0x2232b20, sdispls=0x22332e0, dtype=0x4c000840, rbuf=0x14b8d8810000, rcnts=0x2233380, rdispls=0x22333d0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 3] [job id 1298e74b-8ce0-47cd-a7d5-841895e53139] [Sun Nov 12 08:28:57 2023] [x3204c0s13b0n0] - Abort(674306703) (rank 3 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147be8000000, scnts=0x1210900, sdispls=0x12110c0, dtype=0x4c000840, rbuf=0x147be8810000, rcnts=0x1211160, rdispls=0x12111b0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147be8000000, scnts=0x1210900, sdispls=0x12110c0, dtype=0x4c000840, rbuf=0x147be8810000, rcnts=0x1211160, rdispls=0x12111b0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 8] [job id 1298e74b-8ce0-47cd-a7d5-841895e53139] [Sun Nov 12 08:28:57 2023] [x3204c0s19b0n0] - Abort(472980111) (rank 8 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1532dc000000, scnts=0x1e1ab60, sdispls=0x1e1b5b0, dtype=0x4c000840, rbuf=0x1532dc810000, rcnts=0x1e1b650, rdispls=0x1e1b6a0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1532dc000000, scnts=0x1e1ab60, sdispls=0x1e1b5b0, dtype=0x4c000840, rbuf=0x1532dc810000, rcnts=0x1e1b650, rdispls=0x1e1b6a0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 4] [job id 1298e74b-8ce0-47cd-a7d5-841895e53139] [Sun Nov 12 08:28:57 2023] [x3204c0s13b1n0] - Abort(472980111) (rank 4 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14a7ea000000, scnts=0xaf2e80, sdispls=0xa97cd0, dtype=0x4c000840, rbuf=0x14a7ea810000, rcnts=0xa97d70, rdispls=0xa97dc0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14a7ea000000, scnts=0xaf2e80, sdispls=0xa97cd0, dtype=0x4c000840, rbuf=0x14a7ea810000, rcnts=0xa97d70, rdispls=0xa97dc0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
x3204c0s19b1n0.hsn.cm.polaris.alcf.anl.gov: rank 15 exited with code 255
