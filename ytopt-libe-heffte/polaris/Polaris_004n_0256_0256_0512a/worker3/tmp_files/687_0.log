“RANK= 12 LOCAL_RANK= 0 gpu= 3”
“RANK= 14 LOCAL_RANK= 2 gpu= 1”
“RANK= 13 LOCAL_RANK= 1 gpu= 2”
“RANK= 15 LOCAL_RANK= 3 gpu= 0”
“RANK= 7 LOCAL_RANK= 3 gpu= 0”
“RANK= 4 LOCAL_RANK= 0 gpu= 3”
“RANK= 6 LOCAL_RANK= 2 gpu= 1”
“RANK= 5 LOCAL_RANK= 1 gpu= 2”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 2 8 -outgrid 8 1 2 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 2 8 -outgrid 8 1 2 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 2 8 -outgrid 8 1 2 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 2 8 -outgrid 8 1 2 -n5
“RANK= 11 LOCAL_RANK= 3 gpu= 0”
“RANK= 8 LOCAL_RANK= 0 gpu= 3”
“RANK= 9 LOCAL_RANK= 1 gpu= 2”
“RANK= 10 LOCAL_RANK= 2 gpu= 1”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 2 8 -outgrid 8 1 2 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 2 8 -outgrid 8 1 2 -n5
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 2 8 -outgrid 8 1 2 -n5
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 2 8 -outgrid 8 1 2 -n5
“RANK= 0 LOCAL_RANK= 0 gpu= 3”
“RANK= 3 LOCAL_RANK= 3 gpu= 0”
“RANK= 2 LOCAL_RANK= 2 gpu= 1”
“RANK= 1 LOCAL_RANK= 1 gpu= 2”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 2 8 -outgrid 8 1 2 -n5
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 2 8 -outgrid 8 1 2 -n5
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 2 8 -outgrid 8 1 2 -n5
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 2 8 -outgrid 8 1 2 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 2 8 -outgrid 8 1 2 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 2 8 -outgrid 8 1 2 -n5
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 2 8 -outgrid 8 1 2 -n5
+ speed3d_r2c cufft float 256 256 512 -no-reorder -ingrid 1 2 8 -outgrid 8 1 2 -n5
MPICH ERROR [Rank 7] [job id 67bb7fcc-88fe-4c77-847d-3511d78a0c81] [Sun Nov 12 08:28:59 2023] [x3001c0s19b1n0] - Abort(70326927) (rank 7 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14d978000000, scnts=0xae4fc0, sdispls=0xac6be0, dtype=0x4c000840, rbuf=0x14d978800000, rcnts=0xac6c80, rdispls=0xac6cd0, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14d978000000, scnts=0xae4fc0, sdispls=0xac6be0, dtype=0x4c000840, rbuf=0x14d978800000, rcnts=0xac6c80, rdispls=0xac6cd0, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 11] [job id 67bb7fcc-88fe-4c77-847d-3511d78a0c81] [Sun Nov 12 08:28:59 2023] [x3001c0s1b0n0] - Abort(70326927) (rank 11 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150252000000, scnts=0x1c799e0, sdispls=0x1c94460, dtype=0x4c000840, rbuf=0x150252800000, rcnts=0x1c94500, rdispls=0x1c94550, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150252000000, scnts=0x1c799e0, sdispls=0x1c94460, dtype=0x4c000840, rbuf=0x150252800000, rcnts=0x1c94500, rdispls=0x1c94550, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 13] [job id 67bb7fcc-88fe-4c77-847d-3511d78a0c81] [Sun Nov 12 08:28:59 2023] [x3001c0s1b1n0] - Abort(741415567) (rank 13 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14c9ac000000, scnts=0x150c7f0, sdispls=0x150cfd0, dtype=0x4c000840, rbuf=0x14c9ac800000, rcnts=0x150d070, rdispls=0x150d0c0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14c9ac000000, scnts=0x150c7f0, sdispls=0x150cfd0, dtype=0x4c000840, rbuf=0x14c9ac800000, rcnts=0x150d070, rdispls=0x150d0c0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 6] [job id 67bb7fcc-88fe-4c77-847d-3511d78a0c81] [Sun Nov 12 08:28:59 2023] [x3001c0s19b1n0] - Abort(875633295) (rank 6 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f852000000, scnts=0x186c540, sdispls=0x186cd20, dtype=0x4c000840, rbuf=0x14f852800000, rcnts=0x186cdc0, rdispls=0x186ce10, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f852000000, scnts=0x186c540, sdispls=0x186cd20, dtype=0x4c000840, rbuf=0x14f852800000, rcnts=0x186cdc0, rdispls=0x186ce10, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 0] [job id 67bb7fcc-88fe-4c77-847d-3511d78a0c81] [Sun Nov 12 08:28:59 2023] [x3001c0s19b0n0] - Abort(204544655) (rank 0 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14aefa000000, scnts=0x278b3c0, sdispls=0x278be30, dtype=0x4c000840, rbuf=0x14aefa880000, rcnts=0x278bed0, rdispls=0x278bf20, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14aefa000000, scnts=0x278b3c0, sdispls=0x278be30, dtype=0x4c000840, rbuf=0x14aefa880000, rcnts=0x278bed0, rdispls=0x278bf20, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 9] [job id 67bb7fcc-88fe-4c77-847d-3511d78a0c81] [Sun Nov 12 08:28:59 2023] [x3001c0s1b0n0] - Abort(3218063) (rank 9 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1481e8000000, scnts=0x1b8fd70, sdispls=0x1baa680, dtype=0x4c000840, rbuf=0x1481e8800000, rcnts=0x1baa720, rdispls=0x1baa770, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1481e8000000, scnts=0x1b8fd70, sdispls=0x1baa680, dtype=0x4c000840, rbuf=0x1481e8800000, rcnts=0x1baa720, rdispls=0x1baa770, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 15] [job id 67bb7fcc-88fe-4c77-847d-3511d78a0c81] [Sun Nov 12 08:28:59 2023] [x3001c0s1b1n0] - Abort(942742159) (rank 15 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14aa88000000, scnts=0x1c47f20, sdispls=0x1c44a60, dtype=0x4c000840, rbuf=0x14aa88800000, rcnts=0x1c44b00, rdispls=0x1c44b50, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14aa88000000, scnts=0x1c47f20, sdispls=0x1c44a60, dtype=0x4c000840, rbuf=0x14aa88800000, rcnts=0x1c44b00, rdispls=0x1c44b50, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 1] [job id 67bb7fcc-88fe-4c77-847d-3511d78a0c81] [Sun Nov 12 08:28:59 2023] [x3001c0s19b0n0] - Abort(3218063) (rank 1 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x145898000000, scnts=0x1b82790, sdispls=0x1b82f70, dtype=0x4c000840, rbuf=0x145898800000, rcnts=0x1b97ec0, rdispls=0x1bb32d0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x145898000000, scnts=0x1b82790, sdispls=0x1b82f70, dtype=0x4c000840, rbuf=0x145898800000, rcnts=0x1b97ec0, rdispls=0x1bb32d0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 8] [job id 67bb7fcc-88fe-4c77-847d-3511d78a0c81] [Sun Nov 12 08:28:59 2023] [x3001c0s1b0n0] - Abort(942742159) (rank 8 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1554bc000000, scnts=0x1ce1510, sdispls=0x1ce1f80, dtype=0x4c000840, rbuf=0x1554bc880000, rcnts=0x1c89fc0, rdispls=0x1d0eb00, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1554bc000000, scnts=0x1ce1510, sdispls=0x1ce1f80, dtype=0x4c000840, rbuf=0x1554bc880000, rcnts=0x1c89fc0, rdispls=0x1d0eb00, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 10] [job id 67bb7fcc-88fe-4c77-847d-3511d78a0c81] [Sun Nov 12 08:28:59 2023] [x3001c0s1b0n0] - Abort(875633295) (rank 10 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14a30c000000, scnts=0x23219e0, sdispls=0x233c460, dtype=0x4c000840, rbuf=0x14a30c800000, rcnts=0x233c500, rdispls=0x233c550, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

MPICH ERROR [Rank 4] [job id 67bb7fcc-88fe-4c77-847d-3511d78a0c81] [Sun Nov 12 08:28:59 2023] [x3001c0s19b1n0] - Abort(338762383) (rank 4 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14e6b2000000, scnts=0x2652140, sdispls=0x2652bb0, dtype=0x4c000840, rbuf=0x14e6b2800000, rcnts=0x2652c50, rdispls=0x2652ca0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14a30c000000, scnts=0x23219e0, sdispls=0x233c460, dtype=0x4c000840, rbuf=0x14a30c800000, rcnts=0x233c500, rdispls=0x233c550, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14e6b2000000, scnts=0x2652140, sdispls=0x2652bb0, dtype=0x4c000840, rbuf=0x14e6b2800000, rcnts=0x2652c50, rdispls=0x2652ca0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 5] [job id 67bb7fcc-88fe-4c77-847d-3511d78a0c81] [Sun Nov 12 08:28:59 2023] [x3001c0s19b1n0] - Abort(3218063) (rank 5 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x146942000000, scnts=0xe399e0, sdispls=0xe54460, dtype=0x4c000840, rbuf=0x146942800000, rcnts=0xe54500, rdispls=0xe54550, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x146942000000, scnts=0xe399e0, sdispls=0xe54460, dtype=0x4c000840, rbuf=0x146942800000, rcnts=0xe54500, rdispls=0xe54550, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
x3001c0s19b1n0.hsn.cm.polaris.alcf.anl.gov: rank 7 exited with code 255
(GTL DEBUG: 2) cuIpcOpenMemHandle: invalid resource handle, CUDA_ERROR_INVALID_HANDLE, line no 272
MPICH ERROR [Rank 2] [job id 67bb7fcc-88fe-4c77-847d-3511d78a0c81] [Sun Nov 12 08:28:59 2023] [x3001c0s19b0n0] - Abort(71899650) (rank 2 in comm 0): Fatal error in PMPI_Alltoallv: Invalid count, error stack:
PMPI_Alltoallv(389)..................: MPI_Alltoallv(sbuf=0x1477fa000000, scnts=0xef0540, sdispls=0xef0d20, dtype=0x4c000840, rbuf=0x1477fa800000, rcnts=0xef0dc0, rdispls=0xef0e10, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1143)............: 
MPIC_Irecv(594)......................: 
MPID_Irecv(497)......................: 
MPIDI_irecv_unsafe(160)..............: 
MPIDI_SHM_mpi_irecv(462).............: 
MPIDI_SHM_mpi_imrecv(514)............: 
MPIDI_SHM_mmods_try_matched_recv(167): 
MPIDI_CRAY_Common_lmt_handle_recv(44): 
MPIDI_CRAY_Common_lmt_import_mem(218): 
(unknown)(): Invalid count

aborting job:
Fatal error in PMPI_Alltoallv: Invalid count, error stack:
PMPI_Alltoallv(389)..................: MPI_Alltoallv(sbuf=0x1477fa000000, scnts=0xef0540, sdispls=0xef0d20, dtype=0x4c000840, rbuf=0x1477fa800000, rcnts=0xef0dc0, rdispls=0xef0e10, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1143)............: 
MPIC_Irecv(594)......................: 
MPID_Irecv(497)......................: 
MPIDI_irecv_unsafe(160)..............: 
MPIDI_SHM_mpi_irecv(462).............: 
MPIDI_SHM_mpi_imrecv(514)............: 
MPIDI_SHM_mmods_try_matched_recv(167): 
MPIDI_CRAY_Common_lmt_handle_recv(44): 
MPIDI_CRAY_Common_lmt_import_mem(218): 
(unknown)(): Invalid count
