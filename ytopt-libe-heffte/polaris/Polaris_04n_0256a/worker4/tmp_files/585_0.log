“RANK= 5 LOCAL_RANK= 1 gpu= 2”
“RANK= 4 LOCAL_RANK= 0 gpu= 3”
“RANK= 6 LOCAL_RANK= 2 gpu= 1”
“RANK= 7 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 1 -ingrid 16 1 1 -outgrid 16 1 1
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 1 -ingrid 16 1 1 -outgrid 16 1 1
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 1 -ingrid 16 1 1 -outgrid 16 1 1
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 1 -ingrid 16 1 1 -outgrid 16 1 1
“RANK= 12 LOCAL_RANK= 0 gpu= 3”
“RANK= 14 LOCAL_RANK= 2 gpu= 1”
“RANK= 13 LOCAL_RANK= 1 gpu= 2”
“RANK= 15 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 1 -ingrid 16 1 1 -outgrid 16 1 1
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 1 -ingrid 16 1 1 -outgrid 16 1 1
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 1 -ingrid 16 1 1 -outgrid 16 1 1
+ '[' -z '' ']'
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 1 -ingrid 16 1 1 -outgrid 16 1 1
“RANK= 9 LOCAL_RANK= 1 gpu= 2”
“RANK= 11 LOCAL_RANK= 3 gpu= 0”
“RANK= 10 LOCAL_RANK= 2 gpu= 1”
“RANK= 8 LOCAL_RANK= 0 gpu= 3”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 1 -ingrid 16 1 1 -outgrid 16 1 1
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 1 -ingrid 16 1 1 -outgrid 16 1 1
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 1 -ingrid 16 1 1 -outgrid 16 1 1
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 1 -ingrid 16 1 1 -outgrid 16 1 1
“RANK= 1 LOCAL_RANK= 1 gpu= 2”
“RANK= 3 LOCAL_RANK= 3 gpu= 0”
“RANK= 2 LOCAL_RANK= 2 gpu= 1”
“RANK= 0 LOCAL_RANK= 0 gpu= 3”
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 1 -ingrid 16 1 1 -outgrid 16 1 1
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 1 -ingrid 16 1 1 -outgrid 16 1 1
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 1 -ingrid 16 1 1 -outgrid 16 1 1
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -a2av -slabs -r2c_dir 1 -ingrid 16 1 1 -outgrid 16 1 1
MPICH ERROR [Rank 9] [job id fe79bb6b-c498-4fa7-9e28-a65082b832b9] [Sat Jul  1 22:44:20 2023] [x3010c0s7b0n0] - Abort(137435791) (rank 9 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x153a6ee00000, scnts=0x1d29600, sdispls=0x1d29e90, dtype=0x4c000840, rbuf=0x153a6f208000, rcnts=0x1d29f30, rdispls=0x1d29f80, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x153a6ee00000, scnts=0x1d29600, sdispls=0x1d29e90, dtype=0x4c000840, rbuf=0x153a6f208000, rcnts=0x1d29f30, rdispls=0x1d29f80, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 3] [job id fe79bb6b-c498-4fa7-9e28-a65082b832b9] [Sat Jul  1 22:44:20 2023] [x3010c0s37b0n0] - Abort(1009851023) (rank 3 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x149b1ee00000, scnts=0xc3e680, sdispls=0xc3ee40, dtype=0x4c000840, rbuf=0x149b1f208000, rcnts=0xc3eee0, rdispls=0xc3ef30, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x149b1ee00000, scnts=0xc3e680, sdispls=0xc3ee40, dtype=0x4c000840, rbuf=0x149b1f208000, rcnts=0xc3eee0, rdispls=0xc3ef30, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 7] [job id fe79bb6b-c498-4fa7-9e28-a65082b832b9] [Sat Jul  1 22:44:20 2023] [x3010c0s37b1n0] - Abort(271653519) (rank 7 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x149182e00000, scnts=0x23ae600, sdispls=0x23aed00, dtype=0x4c000840, rbuf=0x149183208000, rcnts=0x23aeda0, rdispls=0x23aedf0, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x149182e00000, scnts=0x23ae600, sdispls=0x23aed00, dtype=0x4c000840, rbuf=0x149183208000, rcnts=0x23aeda0, rdispls=0x23aedf0, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 6] [job id fe79bb6b-c498-4fa7-9e28-a65082b832b9] [Sat Jul  1 22:44:20 2023] [x3010c0s37b1n0] - Abort(808524431) (rank 6 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154764e00000, scnts=0x1676600, sdispls=0x1676d00, dtype=0x4c000840, rbuf=0x154765208000, rcnts=0x1676da0, rdispls=0x1676df0, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154764e00000, scnts=0x1676600, sdispls=0x1676d00, dtype=0x4c000840, rbuf=0x154765208000, rcnts=0x1676da0, rdispls=0x1676df0, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 1] [job id fe79bb6b-c498-4fa7-9e28-a65082b832b9] [Sat Jul  1 22:44:20 2023] [x3010c0s37b0n0] - Abort(875633295) (rank 1 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14a59ee00000, scnts=0x1268680, sdispls=0x1268e40, dtype=0x4c000840, rbuf=0x14a59f208000, rcnts=0x1268ee0, rdispls=0x1268f30, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14a59ee00000, scnts=0x1268680, sdispls=0x1268e40, dtype=0x4c000840, rbuf=0x14a59f208000, rcnts=0x1268ee0, rdispls=0x1268f30, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 15] [job id fe79bb6b-c498-4fa7-9e28-a65082b832b9] [Sat Jul  1 22:44:20 2023] [x3010c0s7b1n0] - Abort(70326927) (rank 15 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14b2eae00000, scnts=0x244f930, sdispls=0x244ff70, dtype=0x4c000840, rbuf=0x14b2eb208000, rcnts=0x2450010, rdispls=0x2450060, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14b2eae00000, scnts=0x244f930, sdispls=0x244ff70, dtype=0x4c000840, rbuf=0x14b2eb208000, rcnts=0x2450010, rdispls=0x2450060, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 13] [job id fe79bb6b-c498-4fa7-9e28-a65082b832b9] [Sat Jul  1 22:44:20 2023] [x3010c0s7b1n0] - Abort(875633295) (rank 13 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14eeeee00000, scnts=0x120d930, sdispls=0x120df70, dtype=0x4c000840, rbuf=0x14eeef208000, rcnts=0x120e010, rdispls=0x120e060, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14eeeee00000, scnts=0x120d930, sdispls=0x120df70, dtype=0x4c000840, rbuf=0x14eeef208000, rcnts=0x120e010, rdispls=0x120e060, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 4] [job id fe79bb6b-c498-4fa7-9e28-a65082b832b9] [Sat Jul  1 22:44:20 2023] [x3010c0s37b1n0] - Abort(472980111) (rank 4 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14de1ae00000, scnts=0x1f0e860, sdispls=0x1eb36f0, dtype=0x4c000840, rbuf=0x14de1b208000, rcnts=0x1eb3790, rdispls=0x1eb37e0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14de1ae00000, scnts=0x1f0e860, sdispls=0x1eb36f0, dtype=0x4c000840, rbuf=0x14de1b208000, rcnts=0x1eb3790, rdispls=0x1eb37e0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 11] [job id fe79bb6b-c498-4fa7-9e28-a65082b832b9] [Sat Jul  1 22:44:20 2023] [x3010c0s7b0n0] - Abort(540088975) (rank 11 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154a54e00000, scnts=0x1d14600, sdispls=0x1d14e90, dtype=0x4c000840, rbuf=0x154a55208000, rcnts=0x1d14f30, rdispls=0x1d14f80, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154a54e00000, scnts=0x1d14600, sdispls=0x1d14e90, dtype=0x4c000840, rbuf=0x154a55208000, rcnts=0x1d14f30, rdispls=0x1d14f80, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 8] [job id fe79bb6b-c498-4fa7-9e28-a65082b832b9] [Sat Jul  1 22:44:20 2023] [x3010c0s7b0n0] - Abort(405871247) (rank 8 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14a05ee00000, scnts=0x15c1cd0, sdispls=0x15c1d20, dtype=0x4c000840, rbuf=0x14a05f208000, rcnts=0x15c1dc0, rdispls=0x15c1e10, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14a05ee00000, scnts=0x15c1cd0, sdispls=0x15c1d20, dtype=0x4c000840, rbuf=0x14a05f208000, rcnts=0x15c1dc0, rdispls=0x15c1e10, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 14] [job id fe79bb6b-c498-4fa7-9e28-a65082b832b9] [Sat Jul  1 22:44:20 2023] [x3010c0s7b1n0] - Abort(338762383) (rank 14 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15524ae00000, scnts=0x11f9930, sdispls=0x11f9f70, dtype=0x4c000840, rbuf=0x15524b208000, rcnts=0x11fa010, rdispls=0x11fa060, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15524ae00000, scnts=0x11f9930, sdispls=0x11f9f70, dtype=0x4c000840, rbuf=0x15524b208000, rcnts=0x11fa010, rdispls=0x11fa060, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 10] [job id fe79bb6b-c498-4fa7-9e28-a65082b832b9] [Sat Jul  1 22:44:20 2023] [x3010c0s7b0n0] - Abort(942742159) (rank 10 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14cf0ae00000, scnts=0x26bd600, sdispls=0x26bde90, dtype=0x4c000840, rbuf=0x14cf0b208000, rcnts=0x26bdf30, rdispls=0x26bdf80, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14cf0ae00000, scnts=0x26bd600, sdispls=0x26bde90, dtype=0x4c000840, rbuf=0x14cf0b208000, rcnts=0x26bdf30, rdispls=0x26bdf80, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 5] [job id fe79bb6b-c498-4fa7-9e28-a65082b832b9] [Sat Jul  1 22:44:20 2023] [x3010c0s37b1n0] - Abort(674306703) (rank 5 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14daaae00000, scnts=0x120d600, sdispls=0x120dd00, dtype=0x4c000840, rbuf=0x14daab208000, rcnts=0x120dda0, rdispls=0x120ddf0, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14daaae00000, scnts=0x120d600, sdispls=0x120dd00, dtype=0x4c000840, rbuf=0x14daab208000, rcnts=0x120dda0, rdispls=0x120ddf0, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 2] [job id fe79bb6b-c498-4fa7-9e28-a65082b832b9] [Sat Jul  1 22:44:20 2023] [x3010c0s37b0n0] - Abort(70326927) (rank 2 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14af6ae00000, scnts=0x14ec680, sdispls=0x14ece40, dtype=0x4c000840, rbuf=0x14af6b208000, rcnts=0x14ecee0, rdispls=0x14ecf30, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14af6ae00000, scnts=0x14ec680, sdispls=0x14ece40, dtype=0x4c000840, rbuf=0x14af6b208000, rcnts=0x14ecee0, rdispls=0x14ecf30, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 12] [job id fe79bb6b-c498-4fa7-9e28-a65082b832b9] [Sat Jul  1 22:44:20 2023] [x3010c0s7b1n0] - Abort(1009851023) (rank 12 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154d6ee00000, scnts=0x1a02600, sdispls=0x1a03050, dtype=0x4c000840, rbuf=0x154d6f208000, rcnts=0x1a030f0, rdispls=0x1a03140, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154d6ee00000, scnts=0x1a02600, sdispls=0x1a03050, dtype=0x4c000840, rbuf=0x154d6f208000, rcnts=0x1a030f0, rdispls=0x1a03140, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 0] [job id fe79bb6b-c498-4fa7-9e28-a65082b832b9] [Sat Jul  1 22:44:20 2023] [x3010c0s37b0n0] - Abort(271653519) (rank 0 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15123ae00000, scnts=0x1233ae0, sdispls=0x1234530, dtype=0x4c000840, rbuf=0x15123b208000, rcnts=0x12345d0, rdispls=0x1234620, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15123ae00000, scnts=0x1233ae0, sdispls=0x1234530, dtype=0x4c000840, rbuf=0x15123b208000, rcnts=0x12345d0, rdispls=0x1234620, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
x3010c0s7b0n0.hsn.cm.polaris.alcf.anl.gov: rank 9 exited with code 255
