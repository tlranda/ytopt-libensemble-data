“RANK= 13 LOCAL_RANK= 1 gpu= 2”
“RANK= 12 LOCAL_RANK= 0 gpu= 3”
“RANK= 14 LOCAL_RANK= 2 gpu= 1”
“RANK= 15 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
“RANK= 8 LOCAL_RANK= 0 gpu= 3”
Shell debugging restarted
+ unset __lmod_vx
“RANK= 9 LOCAL_RANK= 1 gpu= 2”
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -reorder -a2av -pencils -r2c_dir 1 -outgrid 4 4 1 -n5
+ speed3d_r2c cufft float 256 256 256 -reorder -a2av -pencils -r2c_dir 1 -outgrid 4 4 1 -n5
“RANK= 10 LOCAL_RANK= 2 gpu= 1”
+ speed3d_r2c cufft float 256 256 256 -reorder -a2av -pencils -r2c_dir 1 -outgrid 4 4 1 -n5
“RANK= 11 LOCAL_RANK= 3 gpu= 0”
+ speed3d_r2c cufft float 256 256 256 -reorder -a2av -pencils -r2c_dir 1 -outgrid 4 4 1 -n5
“RANK= 1 LOCAL_RANK= 1 gpu= 2”
“RANK= 0 LOCAL_RANK= 0 gpu= 3”
“RANK= 2 LOCAL_RANK= 2 gpu= 1”
+ '[' -z '' ']'
+ case "$-" in
“RANK= 3 LOCAL_RANK= 3 gpu= 0”
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ speed3d_r2c cufft float 256 256 256 -reorder -a2av -pencils -r2c_dir 1 -outgrid 4 4 1 -n5
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -reorder -a2av -pencils -r2c_dir 1 -outgrid 4 4 1 -n5
+ speed3d_r2c cufft float 256 256 256 -reorder -a2av -pencils -r2c_dir 1 -outgrid 4 4 1 -n5
+ speed3d_r2c cufft float 256 256 256 -reorder -a2av -pencils -r2c_dir 1 -outgrid 4 4 1 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
“RANK= 4 LOCAL_RANK= 0 gpu= 3”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
“RANK= 5 LOCAL_RANK= 1 gpu= 2”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
“RANK= 6 LOCAL_RANK= 2 gpu= 1”
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
“RANK= 7 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -reorder -a2av -pencils -r2c_dir 1 -outgrid 4 4 1 -n5
+ speed3d_r2c cufft float 256 256 256 -reorder -a2av -pencils -r2c_dir 1 -outgrid 4 4 1 -n5
+ speed3d_r2c cufft float 256 256 256 -reorder -a2av -pencils -r2c_dir 1 -outgrid 4 4 1 -n5
+ speed3d_r2c cufft float 256 256 256 -reorder -a2av -pencils -r2c_dir 1 -outgrid 4 4 1 -n5
+ '[' -z '' ']'
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 256 256 256 -reorder -a2av -pencils -r2c_dir 1 -outgrid 4 4 1 -n5
+ speed3d_r2c cufft float 256 256 256 -reorder -a2av -pencils -r2c_dir 1 -outgrid 4 4 1 -n5
+ speed3d_r2c cufft float 256 256 256 -reorder -a2av -pencils -r2c_dir 1 -outgrid 4 4 1 -n5
+ speed3d_r2c cufft float 256 256 256 -reorder -a2av -pencils -r2c_dir 1 -outgrid 4 4 1 -n5
MPICH ERROR [Rank 11] [job id cff3d284-eecb-479c-bb93-9834f47ae76d] [Thu Aug  3 06:36:10 2023] [x3001c0s31b0n0] - Abort(1009851023) (rank 11 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14a1ec000000, scnts=0x1503510, sdispls=0x1503cf0, dtype=0x4c000840, rbuf=0x14a1ec400000, rcnts=0x1503d90, rdispls=0x1503de0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14a1ec000000, scnts=0x1503510, sdispls=0x1503cf0, dtype=0x4c000840, rbuf=0x14a1ec400000, rcnts=0x1503d90, rdispls=0x1503de0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 3] [job id cff3d284-eecb-479c-bb93-9834f47ae76d] [Thu Aug  3 06:36:10 2023] [x3001c0s1b1n0] - Abort(3218063) (rank 3 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154012000000, scnts=0x11c33c0, sdispls=0x11c3ba0, dtype=0x4c000840, rbuf=0x154012420000, rcnts=0x11c3c40, rdispls=0x11c3c90, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154012000000, scnts=0x11c33c0, sdispls=0x11c3ba0, dtype=0x4c000840, rbuf=0x154012420000, rcnts=0x11c3c40, rdispls=0x11c3c90, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 1] [job id cff3d284-eecb-479c-bb93-9834f47ae76d] [Thu Aug  3 06:36:10 2023] [x3001c0s1b1n0] - Abort(1009851023) (rank 1 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15534a000000, scnts=0x8dda60, sdispls=0x8de240, dtype=0x4c000840, rbuf=0x15534a420000, rcnts=0x8de2e0, rdispls=0x8de330, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15534a000000, scnts=0x8dda60, sdispls=0x8de240, dtype=0x4c000840, rbuf=0x15534a420000, rcnts=0x8de2e0, rdispls=0x8de330, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 7] [job id cff3d284-eecb-479c-bb93-9834f47ae76d] [Thu Aug  3 06:36:10 2023] [x3001c0s25b0n0] - Abort(674306703) (rank 7 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f7ec000000, scnts=0x1834e10, sdispls=0x18355f0, dtype=0x4c000840, rbuf=0x14f7ec400000, rcnts=0x1835690, rdispls=0x18356e0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f7ec000000, scnts=0x1834e10, sdispls=0x18355f0, dtype=0x4c000840, rbuf=0x14f7ec400000, rcnts=0x1835690, rdispls=0x18356e0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 9] [job id cff3d284-eecb-479c-bb93-9834f47ae76d] [Thu Aug  3 06:36:10 2023] [x3001c0s31b0n0] - Abort(942742159) (rank 9 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14bc3c000000, scnts=0x19e0570, sdispls=0x19e0d50, dtype=0x4c000840, rbuf=0x14bc3c400000, rcnts=0x19e0df0, rdispls=0x19e0e40, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

MPICH ERROR [Rank 14] [job id cff3d284-eecb-479c-bb93-9834f47ae76d] [Thu Aug  3 06:36:10 2023] [x3001c0s31b1n0] - Abort(1009851023) (rank 14 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154678000000, scnts=0xde6a60, sdispls=0xde7240, dtype=0x4c000840, rbuf=0x154678400000, rcnts=0xde72e0, rdispls=0xde7330, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154678000000, scnts=0xde6a60, sdispls=0xde7240, dtype=0x4c000840, rbuf=0x154678400000, rcnts=0xde72e0, rdispls=0xde7330, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14bc3c000000, scnts=0x19e0570, sdispls=0x19e0d50, dtype=0x4c000840, rbuf=0x14bc3c400000, rcnts=0x19e0df0, rdispls=0x19e0e40, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 13] [job id cff3d284-eecb-479c-bb93-9834f47ae76d] [Thu Aug  3 06:36:10 2023] [x3001c0s31b1n0] - Abort(1009851023) (rank 13 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x153458000000, scnts=0x2517510, sdispls=0x2517cf0, dtype=0x4c000840, rbuf=0x153458400000, rcnts=0x2517d90, rdispls=0x2517de0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x153458000000, scnts=0x2517510, sdispls=0x2517cf0, dtype=0x4c000840, rbuf=0x153458400000, rcnts=0x2517d90, rdispls=0x2517de0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
x3001c0s31b0n0.hsn.cm.polaris.alcf.anl.gov: rank 11 exited with code 255
MPICH ERROR [Rank 8] [job id cff3d284-eecb-479c-bb93-9834f47ae76d] [Thu Aug  3 06:36:10 2023] [x3001c0s31b0n0] - Abort(942217743) (rank 8 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389).........: MPI_Alltoallv(sbuf=0x145e28000000, scnts=0x2068cf0, sdispls=0x2069760, dtype=0x4c000840, rbuf=0x145e28400000, rcnts=0x2069800, rdispls=0x2069850, datatype=dtype=0x4c000840, comm=comm=0xc4000009) failed
MPIR_CRAY_Alltoallv(1155)...: 
MPIC_Isend(511).............: 
MPID_Isend_coll(610)........: 
MPIDI_isend_coll_unsafe(176): 
MPIDI_OFI_send_normal(352)..: OFI tagged senddata failed (ofi_send.h:352:MPIDI_OFI_send_normal:No route to host)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389).........: MPI_Alltoallv(sbuf=0x145e28000000, scnts=0x2068cf0, sdispls=0x2069760, dtype=0x4c000840, rbuf=0x145e28400000, rcnts=0x2069800, rdispls=0x2069850, datatype=dtype=0x4c000840, comm=comm=0xc4000009) failed
MPIR_CRAY_Alltoallv(1155)...: 
MPIC_Isend(511).............: 
MPID_Isend_coll(610)........: 
MPIDI_isend_coll_unsafe(176): 
MPIDI_OFI_send_normal(352)..: OFI tagged senddata failed (ofi_send.h:352:MPIDI_OFI_send_normal:No route to host)
MPICH ERROR [Rank 6] [job id cff3d284-eecb-479c-bb93-9834f47ae76d] [Thu Aug  3 06:36:10 2023] [x3001c0s25b0n0] - Abort(405346831) (rank 6 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389).........: MPI_Alltoallv(sbuf=0x150b96000000, scnts=0x876df0, sdispls=0x8775d0, dtype=0x4c000840, rbuf=0x150b96400000, rcnts=0x877670, rdispls=0x8776c0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1155)...: 
MPIC_Isend(511).............: 
MPID_Isend_coll(610)........: 
MPIDI_isend_coll_unsafe(176): 
MPIDI_OFI_send_normal(352)..: OFI tagged senddata failed (ofi_send.h:352:MPIDI_OFI_send_normal:No route to host)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389).........: MPI_Alltoallv(sbuf=0x150b96000000, scnts=0x876df0, sdispls=0x8775d0, dtype=0x4c000840, rbuf=0x150b96400000, rcnts=0x877670, rdispls=0x8776c0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1155)...: 
MPIC_Isend(511).............: 
MPID_Isend_coll(610)........: 
MPIDI_isend_coll_unsafe(176): 
MPIDI_OFI_send_normal(352)..: OFI tagged senddata failed (ofi_send.h:352:MPIDI_OFI_send_normal:No route to host)
