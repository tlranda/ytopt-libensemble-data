“RANK= 20 LOCAL_RANK= 0 gpu= 3”
“RANK= 22 LOCAL_RANK= 2 gpu= 1”
“RANK= 23 LOCAL_RANK= 3 gpu= 0”
“RANK= 21 LOCAL_RANK= 1 gpu= 2”
“RANK= 12 LOCAL_RANK= 0 gpu= 3”
“RANK= 14 LOCAL_RANK= 2 gpu= 1”
“RANK= 15 LOCAL_RANK= 3 gpu= 0”
“RANK= 13 LOCAL_RANK= 1 gpu= 2”
“RANK= 28 LOCAL_RANK= 0 gpu= 3”
“RANK= 29 LOCAL_RANK= 1 gpu= 2”
“RANK= 30 LOCAL_RANK= 2 gpu= 1”
“RANK= 31 LOCAL_RANK= 3 gpu= 0”
“RANK= 16 LOCAL_RANK= 0 gpu= 3”
“RANK= 18 LOCAL_RANK= 2 gpu= 1”
“RANK= 17 LOCAL_RANK= 1 gpu= 2”
“RANK= 19 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
“RANK= 0 LOCAL_RANK= 0 gpu= 3”
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
“RANK= 1 LOCAL_RANK= 1 gpu= 2”
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
“RANK= 2 LOCAL_RANK= 2 gpu= 1”
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
“RANK= 3 LOCAL_RANK= 3 gpu= 0”
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
+ set +x
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
“RANK= 25 LOCAL_RANK= 1 gpu= 2”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
“RANK= 24 LOCAL_RANK= 0 gpu= 3”
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
“RANK= 26 LOCAL_RANK= 2 gpu= 1”
“RANK= 27 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
“RANK= 4 LOCAL_RANK= 0 gpu= 3”
+ set +x
“RANK= 5 LOCAL_RANK= 1 gpu= 2”
Shell debugging restarted
+ unset __lmod_vx
“RANK= 6 LOCAL_RANK= 2 gpu= 1”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
“RANK= 7 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
Shell debugging restarted
+ unset __lmod_vx
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
“RANK= 8 LOCAL_RANK= 0 gpu= 3”
“RANK= 9 LOCAL_RANK= 1 gpu= 2”
“RANK= 10 LOCAL_RANK= 2 gpu= 1”
“RANK= 11 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
+ speed3d_r2c cufft float 512 512 512 -no-reorder -r2c_dir 1 -ingrid 8 4 1 -outgrid 8 4 1 -n5
MPICH ERROR [Rank 13] [job id 0ad97e19-1501-4228-a0a9-1511ddbb19d3] [Thu Aug  3 06:49:25 2023] [x3208c0s1b1n0] - Abort(1009851023) (rank 13 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14cc88000000, scnts=0x1be48c0, sdispls=0x1ba7460, dtype=0x4c000840, rbuf=0x14cc89000000, rcnts=0x1ba7580, rdispls=0x1ba7610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14cc88000000, scnts=0x1be48c0, sdispls=0x1ba7460, dtype=0x4c000840, rbuf=0x14cc89000000, rcnts=0x1ba7580, rdispls=0x1ba7610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 12] [job id 0ad97e19-1501-4228-a0a9-1511ddbb19d3] [Thu Aug  3 06:49:25 2023] [x3208c0s1b1n0] - Abort(338762383) (rank 12 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14ae12000000, scnts=0x1ef2960, sdispls=0x1ef34a0, dtype=0x4c000840, rbuf=0x14ae13000000, rcnts=0x1ef35c0, rdispls=0x1ef3650, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14ae12000000, scnts=0x1ef2960, sdispls=0x1ef34a0, dtype=0x4c000840, rbuf=0x14ae13000000, rcnts=0x1ef35c0, rdispls=0x1ef3650, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 15] [job id 0ad97e19-1501-4228-a0a9-1511ddbb19d3] [Thu Aug  3 06:49:25 2023] [x3208c0s1b1n0] - Abort(70326927) (rank 15 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154140000000, scnts=0x1e787e0, sdispls=0x1e3b460, dtype=0x4c000840, rbuf=0x154141000000, rcnts=0x1e3b580, rdispls=0x1e3b610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154140000000, scnts=0x1e787e0, sdispls=0x1e3b460, dtype=0x4c000840, rbuf=0x154141000000, rcnts=0x1e3b580, rdispls=0x1e3b610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 21] [job id 0ad97e19-1501-4228-a0a9-1511ddbb19d3] [Thu Aug  3 06:49:25 2023] [x3208c0s25b1n0] - Abort(540088975) (rank 21 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x148472000000, scnts=0x1ddc830, sdispls=0x1d9f460, dtype=0x4c000840, rbuf=0x148473000000, rcnts=0x1d9f580, rdispls=0x1d9f610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x148472000000, scnts=0x1ddc830, sdispls=0x1d9f460, dtype=0x4c000840, rbuf=0x148473000000, rcnts=0x1d9f580, rdispls=0x1d9f610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 29] [job id 0ad97e19-1501-4228-a0a9-1511ddbb19d3] [Thu Aug  3 06:49:25 2023] [x3208c0s31b1n0] - Abort(472980111) (rank 29 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14d9d8000000, scnts=0xd008c0, sdispls=0xcc3460, dtype=0x4c000840, rbuf=0x14d9d9000000, rcnts=0xcc3580, rdispls=0xcc3610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14d9d8000000, scnts=0xd008c0, sdispls=0xcc3460, dtype=0x4c000840, rbuf=0x14d9d9000000, rcnts=0xcc3580, rdispls=0xcc3610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 10] [job id 0ad97e19-1501-4228-a0a9-1511ddbb19d3] [Thu Aug  3 06:49:25 2023] [x3208c0s1b0n0] - Abort(808524431) (rank 10 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15100e000000, scnts=0x24fc590, sdispls=0x24fce40, dtype=0x4c000840, rbuf=0x15100f000000, rcnts=0x24fcf60, rdispls=0x24bf210, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15100e000000, scnts=0x24fc590, sdispls=0x24fce40, dtype=0x4c000840, rbuf=0x15100f000000, rcnts=0x24fcf60, rdispls=0x24bf210, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 30] [job id 0ad97e19-1501-4228-a0a9-1511ddbb19d3] [Thu Aug  3 06:49:25 2023] [x3208c0s31b1n0] - Abort(1009851023) (rank 30 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14c5a0000000, scnts=0x161b8c0, sdispls=0x15de460, dtype=0x4c000840, rbuf=0x14c5a1000000, rcnts=0x15de580, rdispls=0x15de610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14c5a0000000, scnts=0x161b8c0, sdispls=0x15de460, dtype=0x4c000840, rbuf=0x14c5a1000000, rcnts=0x15de580, rdispls=0x15de610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 6] [job id 0ad97e19-1501-4228-a0a9-1511ddbb19d3] [Thu Aug  3 06:49:25 2023] [x3208c0s19b0n0] - Abort(271653519) (rank 6 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14db26000000, scnts=0x1b9c270, sdispls=0x1b9cb20, dtype=0x4c000840, rbuf=0x14db27040000, rcnts=0x1b9cc40, rdispls=0x1b9ccd0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14db26000000, scnts=0x1b9c270, sdispls=0x1b9cb20, dtype=0x4c000840, rbuf=0x14db27040000, rcnts=0x1b9cc40, rdispls=0x1b9ccd0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 0] [job id 0ad97e19-1501-4228-a0a9-1511ddbb19d3] [Thu Aug  3 06:49:25 2023] [x3208c0s13b1n0] - Abort(1009851023) (rank 0 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x146400000000, scnts=0x21ae540, sdispls=0x2192f20, dtype=0x4c000840, rbuf=0x146401040000, rcnts=0x21d0f20, rdispls=0x21cb250, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x146400000000, scnts=0x21ae540, sdispls=0x2192f20, dtype=0x4c000840, rbuf=0x146401040000, rcnts=0x21d0f20, rdispls=0x21cb250, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 16] [job id 0ad97e19-1501-4228-a0a9-1511ddbb19d3] [Thu Aug  3 06:49:25 2023] [x3208c0s25b0n0] - Abort(204544655) (rank 16 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x145582000000, scnts=0x2517d90, sdispls=0x2518880, dtype=0x4c000840, rbuf=0x145583000000, rcnts=0x25189a0, rdispls=0x2518a30, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x145582000000, scnts=0x2517d90, sdispls=0x2518880, dtype=0x4c000840, rbuf=0x145583000000, rcnts=0x25189a0, rdispls=0x2518a30, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 17] [job id 0ad97e19-1501-4228-a0a9-1511ddbb19d3] [Thu Aug  3 06:49:25 2023] [x3208c0s25b0n0] - Abort(540088975) (rank 17 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x152ba8000000, scnts=0x1ef98c0, sdispls=0x1ebc460, dtype=0x4c000840, rbuf=0x152ba9000000, rcnts=0x1ebc580, rdispls=0x1ebc610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x152ba8000000, scnts=0x1ef98c0, sdispls=0x1ebc460, dtype=0x4c000840, rbuf=0x152ba9000000, rcnts=0x1ebc580, rdispls=0x1ebc610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 1] [job id 0ad97e19-1501-4228-a0a9-1511ddbb19d3] [Thu Aug  3 06:49:25 2023] [x3208c0s13b1n0] - Abort(204544655) (rank 1 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14b5ac000000, scnts=0x8ac8c0, sdispls=0x8a58a0, dtype=0x4c000840, rbuf=0x14b5ad040000, rcnts=0x8a59c0, rdispls=0x8a5a50, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14b5ac000000, scnts=0x8ac8c0, sdispls=0x8a58a0, dtype=0x4c000840, rbuf=0x14b5ad040000, rcnts=0x8a59c0, rdispls=0x8a5a50, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 31] [job id 0ad97e19-1501-4228-a0a9-1511ddbb19d3] [Thu Aug  3 06:49:25 2023] [x3208c0s31b1n0] - Abort(70326927) (rank 31 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14578e000000, scnts=0xcc1880, sdispls=0xc84460, dtype=0x4c000840, rbuf=0x14578f000000, rcnts=0xc84580, rdispls=0xc84610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14578e000000, scnts=0xcc1880, sdispls=0xc84460, dtype=0x4c000840, rbuf=0x14578f000000, rcnts=0xc84580, rdispls=0xc84610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 20] [job id 0ad97e19-1501-4228-a0a9-1511ddbb19d3] [Thu Aug  3 06:49:25 2023] [x3208c0s25b1n0] - Abort(741415567) (rank 20 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14e75e000000, scnts=0xccfcc0, sdispls=0xcd07e0, dtype=0x4c000840, rbuf=0x14e75f000000, rcnts=0xcd0900, rdispls=0xcd0990, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14e75e000000, scnts=0xccfcc0, sdispls=0xcd07e0, dtype=0x4c000840, rbuf=0x14e75f000000, rcnts=0xcd0900, rdispls=0xcd0990, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 5] [job id 0ad97e19-1501-4228-a0a9-1511ddbb19d3] [Thu Aug  3 06:49:25 2023] [x3208c0s19b0n0] - Abort(1009851023) (rank 5 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x148fce000000, scnts=0x12f8950, sdispls=0x12bb460, dtype=0x4c000840, rbuf=0x148fcf040000, rcnts=0x12bb580, rdispls=0x12bb610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x148fce000000, scnts=0x12f8950, sdispls=0x12bb460, dtype=0x4c000840, rbuf=0x148fcf040000, rcnts=0x12bb580, rdispls=0x12bb610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 2] [job id 0ad97e19-1501-4228-a0a9-1511ddbb19d3] [Thu Aug  3 06:49:25 2023] [x3208c0s13b1n0] - Abort(70326927) (rank 2 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14e990000000, scnts=0x23c3880, sdispls=0x2386460, dtype=0x4c000840, rbuf=0x14e991040000, rcnts=0x2386580, rdispls=0x2386610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14e990000000, scnts=0x23c3880, sdispls=0x2386460, dtype=0x4c000840, rbuf=0x14e991040000, rcnts=0x2386580, rdispls=0x2386610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 26] [job id 0ad97e19-1501-4228-a0a9-1511ddbb19d3] [Thu Aug  3 06:49:25 2023] [x3208c0s31b0n0] - Abort(204544655) (rank 26 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150c78000000, scnts=0x134fb00, sdispls=0x1312610, dtype=0x4c000840, rbuf=0x150c79000000, rcnts=0x1312730, rdispls=0x13127c0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150c78000000, scnts=0x134fb00, sdispls=0x1312610, dtype=0x4c000840, rbuf=0x150c79000000, rcnts=0x1312730, rdispls=0x13127c0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 4] [job id 0ad97e19-1501-4228-a0a9-1511ddbb19d3] [Thu Aug  3 06:49:25 2023] [x3208c0s19b0n0] - Abort(271653519) (rank 4 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14c4ae000000, scnts=0xb7d360, sdispls=0xb7de80, dtype=0x4c000840, rbuf=0x14c4af040000, rcnts=0xb7dfa0, rdispls=0xb7e030, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14c4ae000000, scnts=0xb7d360, sdispls=0xb7de80, dtype=0x4c000840, rbuf=0x14c4af040000, rcnts=0xb7dfa0, rdispls=0xb7e030, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 27] [job id 0ad97e19-1501-4228-a0a9-1511ddbb19d3] [Thu Aug  3 06:49:25 2023] [x3208c0s31b0n0] - Abort(70326927) (rank 27 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150280000000, scnts=0x16748c0, sdispls=0x1637460, dtype=0x4c000840, rbuf=0x150281000000, rcnts=0x1637580, rdispls=0x1637610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150280000000, scnts=0x16748c0, sdispls=0x1637460, dtype=0x4c000840, rbuf=0x150281000000, rcnts=0x1637580, rdispls=0x1637610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 7] [job id 0ad97e19-1501-4228-a0a9-1511ddbb19d3] [Thu Aug  3 06:49:25 2023] [x3208c0s19b0n0] - Abort(405871247) (rank 7 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14ca3c000000, scnts=0x17bb8c0, sdispls=0x177e460, dtype=0x4c000840, rbuf=0x14ca3d040000, rcnts=0x177e580, rdispls=0x177e610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14ca3c000000, scnts=0x17bb8c0, sdispls=0x177e460, dtype=0x4c000840, rbuf=0x14ca3d040000, rcnts=0x177e580, rdispls=0x177e610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 18] [job id 0ad97e19-1501-4228-a0a9-1511ddbb19d3] [Thu Aug  3 06:49:25 2023] [x3208c0s25b0n0] - Abort(271653519) (rank 18 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150088000000, scnts=0x140c9e0, sdispls=0x13cf4f0, dtype=0x4c000840, rbuf=0x150089000000, rcnts=0x13cf610, rdispls=0x13cf6a0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150088000000, scnts=0x140c9e0, sdispls=0x13cf4f0, dtype=0x4c000840, rbuf=0x150089000000, rcnts=0x13cf610, rdispls=0x13cf6a0, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 19] [job id 0ad97e19-1501-4228-a0a9-1511ddbb19d3] [Thu Aug  3 06:49:25 2023] [x3208c0s25b0n0] - Abort(1009326607) (rank 19 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389).........: MPI_Alltoallv(sbuf=0x147a08000000, scnts=0x11548c0, sdispls=0x1117460, dtype=0x4c000840, rbuf=0x147a09000000, rcnts=0x1117580, rdispls=0x1117610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1155)...: 
MPIC_Isend(511).............: 
MPID_Isend_coll(610)........: 
MPIDI_isend_coll_unsafe(176): 
MPIDI_OFI_send_normal(352)..: OFI tagged senddata failed (ofi_send.h:352:MPIDI_OFI_send_normal:No route to host)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389).........: MPI_Alltoallv(sbuf=0x147a08000000, scnts=0x11548c0, sdispls=0x1117460, dtype=0x4c000840, rbuf=0x147a09000000, rcnts=0x1117580, rdispls=0x1117610, datatype=dtype=0x4c000840, comm=comm=0xc4000001) failed
MPIR_CRAY_Alltoallv(1155)...: 
MPIC_Isend(511).............: 
MPID_Isend_coll(610)........: 
MPIDI_isend_coll_unsafe(176): 
MPIDI_OFI_send_normal(352)..: OFI tagged senddata failed (ofi_send.h:352:MPIDI_OFI_send_normal:No route to host)
x3208c0s1b0n0.hsn.cm.polaris.alcf.anl.gov: rank 10 exited with code 255
