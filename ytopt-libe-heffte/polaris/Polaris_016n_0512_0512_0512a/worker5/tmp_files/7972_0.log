“RANK= 52 LOCAL_RANK= 0 gpu= 3”
“RANK= 53 LOCAL_RANK= 1 gpu= 2”
“RANK= 55 LOCAL_RANK= 3 gpu= 0”
“RANK= 40 LOCAL_RANK= 0 gpu= 3”
“RANK= 20 LOCAL_RANK= 0 gpu= 3”
“RANK= 43 LOCAL_RANK= 3 gpu= 0”
“RANK= 54 LOCAL_RANK= 2 gpu= 1”
“RANK= 22 LOCAL_RANK= 2 gpu= 1”
“RANK= 42 LOCAL_RANK= 2 gpu= 1”
“RANK= 21 LOCAL_RANK= 1 gpu= 2”
“RANK= 41 LOCAL_RANK= 1 gpu= 2”
“RANK= 23 LOCAL_RANK= 3 gpu= 0”
“RANK= 13 LOCAL_RANK= 1 gpu= 2”
“RANK= 12 LOCAL_RANK= 0 gpu= 3”
“RANK= 14 LOCAL_RANK= 2 gpu= 1”
“RANK= 15 LOCAL_RANK= 3 gpu= 0”
“RANK= 32 LOCAL_RANK= 0 gpu= 3”
“RANK= 33 LOCAL_RANK= 1 gpu= 2”
“RANK= 34 LOCAL_RANK= 2 gpu= 1”
“RANK= 35 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
“RANK= 48 LOCAL_RANK= 0 gpu= 3”
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -z '' ']'
+ case "$-" in
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ set +x
+ '[' -n x ']'
+ set +x
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
“RANK= 49 LOCAL_RANK= 1 gpu= 2”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
“RANK= 50 LOCAL_RANK= 2 gpu= 1”
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
“RANK= 51 LOCAL_RANK= 3 gpu= 0”
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
“RANK= 16 LOCAL_RANK= 0 gpu= 3”
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
“RANK= 17 LOCAL_RANK= 1 gpu= 2”
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
Shell debugging restarted
Shell debugging restarted
+ unset __lmod_vx
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
“RANK= 18 LOCAL_RANK= 2 gpu= 1”
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
Shell debugging restarted
+ unset __lmod_vx
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
“RANK= 60 LOCAL_RANK= 0 gpu= 3”
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
“RANK= 19 LOCAL_RANK= 3 gpu= 0”
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
Shell debugging restarted
+ unset __lmod_vx
“RANK= 63 LOCAL_RANK= 3 gpu= 0”
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
“RANK= 62 LOCAL_RANK= 2 gpu= 1”
“RANK= 61 LOCAL_RANK= 1 gpu= 2”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
“RANK= 24 LOCAL_RANK= 0 gpu= 3”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
“RANK= 27 LOCAL_RANK= 3 gpu= 0”
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
“RANK= 26 LOCAL_RANK= 2 gpu= 1”
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
“RANK= 25 LOCAL_RANK= 1 gpu= 2”
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ '[' -z '' ']'
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
“RANK= 56 LOCAL_RANK= 0 gpu= 3”
“RANK= 58 LOCAL_RANK= 2 gpu= 1”
Shell debugging restarted
+ unset __lmod_vx
“RANK= 57 LOCAL_RANK= 1 gpu= 2”
“RANK= 59 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ '[' -z '' ']'
+ case "$-" in
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ set +x
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
Shell debugging restarted
“RANK= 44 LOCAL_RANK= 0 gpu= 3”
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
“RANK= 45 LOCAL_RANK= 1 gpu= 2”
“RANK= 46 LOCAL_RANK= 2 gpu= 1”
“RANK= 47 LOCAL_RANK= 3 gpu= 0”
“RANK= 28 LOCAL_RANK= 0 gpu= 3”
“RANK= 30 LOCAL_RANK= 2 gpu= 1”
“RANK= 31 LOCAL_RANK= 3 gpu= 0”
“RANK= 29 LOCAL_RANK= 1 gpu= 2”
“RANK= 39 LOCAL_RANK= 3 gpu= 0”
“RANK= 36 LOCAL_RANK= 0 gpu= 3”
“RANK= 37 LOCAL_RANK= 1 gpu= 2”
“RANK= 38 LOCAL_RANK= 2 gpu= 1”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
“RANK= 8 LOCAL_RANK= 0 gpu= 3”
+ set +x
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ set +x
“RANK= 9 LOCAL_RANK= 1 gpu= 2”
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
“RANK= 10 LOCAL_RANK= 2 gpu= 1”
Shell debugging restarted
+ unset __lmod_vx
“RANK= 11 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
“RANK= 0 LOCAL_RANK= 0 gpu= 3”
“RANK= 1 LOCAL_RANK= 1 gpu= 2”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
“RANK= 2 LOCAL_RANK= 2 gpu= 1”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
“RANK= 3 LOCAL_RANK= 3 gpu= 0”
Shell debugging restarted
+ unset __lmod_vx
“RANK= 4 LOCAL_RANK= 0 gpu= 3”
Shell debugging restarted
+ unset __lmod_vx
“RANK= 5 LOCAL_RANK= 1 gpu= 2”
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
“RANK= 6 LOCAL_RANK= 2 gpu= 1”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
“RANK= 7 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ '[' -z '' ']'
+ case "$-" in
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 4 16 1 -outgrid 32 1 2 -n5
MPICH ERROR [Rank 38] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s7b0n0] - Abort(204544655) (rank 38 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x149a86000000, scnts=0x1721e00, sdispls=0x170b400, dtype=0x4c000840, rbuf=0x149a86800000, rcnts=0x170b620, rdispls=0x170b730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x149a86000000, scnts=0x1721e00, sdispls=0x170b400, dtype=0x4c000840, rbuf=0x149a86800000, rcnts=0x170b620, rdispls=0x170b730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 47] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3005c0s13b1n0] - Abort(1009851023) (rank 47 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1498fe000000, scnts=0xaa9db0, sdispls=0xa931e0, dtype=0x4c000840, rbuf=0x1498fe800000, rcnts=0xa93400, rdispls=0xa93510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1498fe000000, scnts=0xaa9db0, sdispls=0xa931e0, dtype=0x4c000840, rbuf=0x1498fe800000, rcnts=0xa93400, rdispls=0xa93510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 46] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3005c0s13b1n0] - Abort(70326927) (rank 46 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154884000000, scnts=0x11e3e00, sdispls=0x11cd400, dtype=0x4c000840, rbuf=0x154884800000, rcnts=0x11cd620, rdispls=0x11cd730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154884000000, scnts=0x11e3e00, sdispls=0x11cd400, dtype=0x4c000840, rbuf=0x154884800000, rcnts=0x11cd620, rdispls=0x11cd730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 5] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s1b0n0] - Abort(405871247) (rank 5 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x153b46000000, scnts=0xda1db0, sdispls=0xd8b1e0, dtype=0x4c000840, rbuf=0x153b46810000, rcnts=0xd8b400, rdispls=0xd8b510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x153b46000000, scnts=0xda1db0, sdispls=0xd8b1e0, dtype=0x4c000840, rbuf=0x153b46810000, rcnts=0xd8b400, rdispls=0xd8b510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 40] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s7b1n0] - Abort(741415567) (rank 40 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x148bd6000000, scnts=0x147bef0, sdispls=0x13900e0, dtype=0x4c000840, rbuf=0x148bd6800000, rcnts=0x1390300, rdispls=0x1390410, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x148bd6000000, scnts=0x147bef0, sdispls=0x13900e0, dtype=0x4c000840, rbuf=0x148bd6800000, rcnts=0x1390300, rdispls=0x1390410, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 41] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s7b1n0] - Abort(808524431) (rank 41 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147496000000, scnts=0x2327db0, sdispls=0x23111e0, dtype=0x4c000840, rbuf=0x147496800000, rcnts=0x2311400, rdispls=0x2311510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147496000000, scnts=0x2327db0, sdispls=0x23111e0, dtype=0x4c000840, rbuf=0x147496800000, rcnts=0x2311400, rdispls=0x2311510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 43] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s7b1n0] - Abort(137435791) (rank 43 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f246000000, scnts=0x1005db0, sdispls=0xfef1e0, dtype=0x4c000840, rbuf=0x14f246800000, rcnts=0xfef400, rdispls=0xfef510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f246000000, scnts=0x1005db0, sdispls=0xfef1e0, dtype=0x4c000840, rbuf=0x14f246800000, rcnts=0xfef400, rdispls=0xfef510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 6] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s1b0n0] - Abort(137435791) (rank 6 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154aae000000, scnts=0x1cc6e00, sdispls=0x1cb0400, dtype=0x4c000840, rbuf=0x154aae810000, rcnts=0x1cb0620, rdispls=0x1cb0730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154aae000000, scnts=0x1cc6e00, sdispls=0x1cb0400, dtype=0x4c000840, rbuf=0x154aae810000, rcnts=0x1cb0620, rdispls=0x1cb0730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 44] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3005c0s13b1n0] - Abort(1009851023) (rank 44 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150d5e000000, scnts=0x23e9680, sdispls=0x23d14f0, dtype=0x4c000840, rbuf=0x150d5e800000, rcnts=0x23d1710, rdispls=0x23d1820, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150d5e000000, scnts=0x23e9680, sdispls=0x23d14f0, dtype=0x4c000840, rbuf=0x150d5e800000, rcnts=0x23d1710, rdispls=0x23d1820, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 60] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3005c0s1b1n0] - Abort(808524431) (rank 60 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x152274000000, scnts=0x1035680, sdispls=0x101dd10, dtype=0x4c000840, rbuf=0x152274800000, rcnts=0x103b120, rdispls=0x103b230, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x152274000000, scnts=0x1035680, sdispls=0x101dd10, dtype=0x4c000840, rbuf=0x152274800000, rcnts=0x103b120, rdispls=0x103b230, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 61] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3005c0s1b1n0] - Abort(405871247) (rank 61 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150b36000000, scnts=0x2221db0, sdispls=0x220b1e0, dtype=0x4c000840, rbuf=0x150b36800000, rcnts=0x220b400, rdispls=0x220b510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150b36000000, scnts=0x2221db0, sdispls=0x220b1e0, dtype=0x4c000840, rbuf=0x150b36800000, rcnts=0x220b400, rdispls=0x220b510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 7] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s1b0n0] - Abort(70326927) (rank 7 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14c886000000, scnts=0xce3db0, sdispls=0xccd1e0, dtype=0x4c000840, rbuf=0x14c886810000, rcnts=0xccd400, rdispls=0xccd510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14c886000000, scnts=0xce3db0, sdispls=0xccd1e0, dtype=0x4c000840, rbuf=0x14c886810000, rcnts=0xccd400, rdispls=0xccd510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 35] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s37b1n0] - Abort(137435791) (rank 35 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f8b6000000, scnts=0x1521db0, sdispls=0x150b1e0, dtype=0x4c000840, rbuf=0x14f8b6800000, rcnts=0x150b400, rdispls=0x150b510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f8b6000000, scnts=0x1521db0, sdispls=0x150b1e0, dtype=0x4c000840, rbuf=0x14f8b6800000, rcnts=0x150b400, rdispls=0x150b510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 12] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s25b0n0] - Abort(204544655) (rank 12 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15347e000000, scnts=0x1521e90, sdispls=0x143e9e0, dtype=0x4c000840, rbuf=0x15347e810000, rcnts=0x143ec00, rdispls=0x143ed10, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15347e000000, scnts=0x1521e90, sdispls=0x143e9e0, dtype=0x4c000840, rbuf=0x15347e810000, rcnts=0x143ec00, rdispls=0x143ed10, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 21] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s31b0n0] - Abort(338762383) (rank 21 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14feb6000000, scnts=0x1541db0, sdispls=0x152b1e0, dtype=0x4c000840, rbuf=0x14feb6810000, rcnts=0x152b400, rdispls=0x152b510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14feb6000000, scnts=0x1541db0, sdispls=0x152b1e0, dtype=0x4c000840, rbuf=0x14feb6810000, rcnts=0x152b400, rdispls=0x152b510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 25] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s31b1n0] - Abort(137435791) (rank 25 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x145536000000, scnts=0x1c3adb0, sdispls=0x1c241e0, dtype=0x4c000840, rbuf=0x145536810000, rcnts=0x1c24400, rdispls=0x1c24510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x145536000000, scnts=0x1c3adb0, sdispls=0x1c241e0, dtype=0x4c000840, rbuf=0x145536810000, rcnts=0x1c24400, rdispls=0x1c24510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 3] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s19b1n0] - Abort(405871247) (rank 3 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14791e000000, scnts=0xbe4e20, sdispls=0xbcbcd0, dtype=0x4c000840, rbuf=0x14791e810000, rcnts=0xbcbef0, rdispls=0xbcc000, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14791e000000, scnts=0xbe4e20, sdispls=0xbcbcd0, dtype=0x4c000840, rbuf=0x14791e810000, rcnts=0xbcbef0, rdispls=0xbcc000, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 52] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3005c0s19b1n0] - Abort(338762383) (rank 52 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14c414000000, scnts=0xbebe50, sdispls=0xb082b0, dtype=0x4c000840, rbuf=0x14c414800000, rcnts=0xb084d0, rdispls=0xb085e0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14c414000000, scnts=0xbebe50, sdispls=0xb082b0, dtype=0x4c000840, rbuf=0x14c414800000, rcnts=0xb084d0, rdispls=0xb085e0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 9] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s1b1n0] - Abort(1009851023) (rank 9 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x145ff6000000, scnts=0xdc9db0, sdispls=0xdb31e0, dtype=0x4c000840, rbuf=0x145ff6810000, rcnts=0xdb3400, rdispls=0xdb3510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x145ff6000000, scnts=0xdc9db0, sdispls=0xdb31e0, dtype=0x4c000840, rbuf=0x145ff6810000, rcnts=0xdb3400, rdispls=0xdb3510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 54] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3005c0s19b1n0] - Abort(808524431) (rank 54 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1550f2000000, scnts=0xc4ee00, sdispls=0xc38400, dtype=0x4c000840, rbuf=0x1550f2800000, rcnts=0xc38620, rdispls=0xc38730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1550f2000000, scnts=0xc4ee00, sdispls=0xc38400, dtype=0x4c000840, rbuf=0x1550f2800000, rcnts=0xc38620, rdispls=0xc38730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 57] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3005c0s1b0n0] - Abort(607197839) (rank 57 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14da04000000, scnts=0x1cefdb0, sdispls=0x1cd91e0, dtype=0x4c000840, rbuf=0x14da04800000, rcnts=0x1cd9400, rdispls=0x1cd9510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14da04000000, scnts=0x1cefdb0, sdispls=0x1cd91e0, dtype=0x4c000840, rbuf=0x14da04800000, rcnts=0x1cd9400, rdispls=0x1cd9510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 59] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3005c0s1b0n0] - Abort(204544655) (rank 59 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14fb06000000, scnts=0x19fcdb0, sdispls=0x19e61e0, dtype=0x4c000840, rbuf=0x14fb06800000, rcnts=0x19e6400, rdispls=0x19e6510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14fb06000000, scnts=0x19fcdb0, sdispls=0x19e61e0, dtype=0x4c000840, rbuf=0x14fb06800000, rcnts=0x19e6400, rdispls=0x19e6510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 2] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s19b1n0] - Abort(3218063) (rank 2 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14e346000000, scnts=0x1bf2e20, sdispls=0x1bd9cd0, dtype=0x4c000840, rbuf=0x14e346810000, rcnts=0x1bd9ef0, rdispls=0x1bda000, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14e346000000, scnts=0x1bf2e20, sdispls=0x1bd9cd0, dtype=0x4c000840, rbuf=0x14e346810000, rcnts=0x1bd9ef0, rdispls=0x1bda000, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 0] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s19b1n0] - Abort(875633295) (rank 0 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1533f4000000, scnts=0x14c3b80, sdispls=0x1667d10, dtype=0x4c000840, rbuf=0x1533f4810000, rcnts=0x14c3ed0, rdispls=0x15d5120, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1533f4000000, scnts=0x14c3b80, sdispls=0x1667d10, dtype=0x4c000840, rbuf=0x1533f4810000, rcnts=0x14c3ed0, rdispls=0x15d5120, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 11] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s1b1n0] - Abort(70326927) (rank 11 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14aff6000000, scnts=0x2260db0, sdispls=0x224a1e0, dtype=0x4c000840, rbuf=0x14aff6810000, rcnts=0x224a400, rdispls=0x224a510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14aff6000000, scnts=0x2260db0, sdispls=0x224a1e0, dtype=0x4c000840, rbuf=0x14aff6810000, rcnts=0x224a400, rdispls=0x224a510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 55] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3005c0s19b1n0] - Abort(338762383) (rank 55 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150ee4000000, scnts=0x86adb0, sdispls=0x8541e0, dtype=0x4c000840, rbuf=0x150ee4800000, rcnts=0x854400, rdispls=0x854510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150ee4000000, scnts=0x86adb0, sdispls=0x8541e0, dtype=0x4c000840, rbuf=0x150ee4800000, rcnts=0x854400, rdispls=0x854510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 18] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s25b1n0] - Abort(271653519) (rank 18 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x151bee000000, scnts=0x1c44e00, sdispls=0x1c2e400, dtype=0x4c000840, rbuf=0x151bee810000, rcnts=0x1c2e620, rdispls=0x1c2e730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x151bee000000, scnts=0x1c44e00, sdispls=0x1c2e400, dtype=0x4c000840, rbuf=0x151bee810000, rcnts=0x1c2e620, rdispls=0x1c2e730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 62] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3005c0s1b1n0] - Abort(540088975) (rank 62 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1546be000000, scnts=0x234de00, sdispls=0x2337400, dtype=0x4c000840, rbuf=0x1546be800000, rcnts=0x2337620, rdispls=0x2337730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1546be000000, scnts=0x234de00, sdispls=0x2337400, dtype=0x4c000840, rbuf=0x1546be800000, rcnts=0x2337620, rdispls=0x2337730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 30] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s37b0n0] - Abort(942742159) (rank 30 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14ad1e000000, scnts=0x822e00, sdispls=0x80c400, dtype=0x4c000840, rbuf=0x14ad1e810000, rcnts=0x80c620, rdispls=0x80c730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14ad1e000000, scnts=0x822e00, sdispls=0x80c400, dtype=0x4c000840, rbuf=0x14ad1e810000, rcnts=0x80c620, rdispls=0x80c730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 42] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s7b1n0] - Abort(741415567) (rank 42 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1470ee000000, scnts=0x20e6e00, sdispls=0x20d0400, dtype=0x4c000840, rbuf=0x1470ee800000, rcnts=0x20d0620, rdispls=0x20d0730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1470ee000000, scnts=0x20e6e00, sdispls=0x20d0400, dtype=0x4c000840, rbuf=0x1470ee800000, rcnts=0x20d0620, rdispls=0x20d0730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 45] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3005c0s13b1n0] - Abort(137435791) (rank 45 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x145bf4000000, scnts=0x1c39db0, sdispls=0x1c231e0, dtype=0x4c000840, rbuf=0x145bf4800000, rcnts=0x1c23400, rdispls=0x1c23510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x145bf4000000, scnts=0x1c39db0, sdispls=0x1c231e0, dtype=0x4c000840, rbuf=0x145bf4800000, rcnts=0x1c23400, rdispls=0x1c23510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 39] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s7b0n0] - Abort(607197839) (rank 39 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14c316000000, scnts=0x179ddb0, sdispls=0x17871e0, dtype=0x4c000840, rbuf=0x14c316800000, rcnts=0x1787400, rdispls=0x1787510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14c316000000, scnts=0x179ddb0, sdispls=0x17871e0, dtype=0x4c000840, rbuf=0x14c316800000, rcnts=0x1787400, rdispls=0x1787510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 10] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s1b1n0] - Abort(405871247) (rank 10 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14bc9e000000, scnts=0x1b07e00, sdispls=0x1af1400, dtype=0x4c000840, rbuf=0x14bc9e810000, rcnts=0x1af1620, rdispls=0x1af1730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

MPICH ERROR [Rank 51] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3005c0s19b0n0] - Abort(540088975) (rank 51 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x149ef4000000, scnts=0x26c7db0, sdispls=0x26b11e0, dtype=0x4c000840, rbuf=0x149ef4800000, rcnts=0x26b1400, rdispls=0x26b1510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x149ef4000000, scnts=0x26c7db0, sdispls=0x26b11e0, dtype=0x4c000840, rbuf=0x149ef4800000, rcnts=0x26b1400, rdispls=0x26b1510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14bc9e000000, scnts=0x1b07e00, sdispls=0x1af1400, dtype=0x4c000840, rbuf=0x14bc9e810000, rcnts=0x1af1620, rdispls=0x1af1730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 28] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s37b0n0] - Abort(70326927) (rank 28 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x146af4000000, scnts=0xc9e6d0, sdispls=0xcc4730, dtype=0x4c000840, rbuf=0x146af4810000, rcnts=0xcc4950, rdispls=0xcc4a60, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x146af4000000, scnts=0xc9e6d0, sdispls=0xcc4730, dtype=0x4c000840, rbuf=0x146af4810000, rcnts=0xcc4950, rdispls=0xcc4a60, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 22] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s31b0n0] - Abort(271653519) (rank 22 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x152c44000000, scnts=0x2042e00, sdispls=0x202c400, dtype=0x4c000840, rbuf=0x152c44810000, rcnts=0x202c620, rdispls=0x202c730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x152c44000000, scnts=0x2042e00, sdispls=0x202c400, dtype=0x4c000840, rbuf=0x152c44810000, rcnts=0x202c620, rdispls=0x202c730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 32] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s37b1n0] - Abort(70326927) (rank 32 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14edde000000, scnts=0x1276680, sdispls=0x127c6b0, dtype=0x4c000840, rbuf=0x14edde800000, rcnts=0x127c8d0, rdispls=0x127c9e0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14edde000000, scnts=0x1276680, sdispls=0x127c6b0, dtype=0x4c000840, rbuf=0x14edde800000, rcnts=0x127c8d0, rdispls=0x127c9e0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 49] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3005c0s19b0n0] - Abort(540088975) (rank 49 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14b536000000, scnts=0x1b96db0, sdispls=0x1b801e0, dtype=0x4c000840, rbuf=0x14b536800000, rcnts=0x1b80400, rdispls=0x1b80510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14b536000000, scnts=0x1b96db0, sdispls=0x1b801e0, dtype=0x4c000840, rbuf=0x14b536800000, rcnts=0x1b80400, rdispls=0x1b80510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 34] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s37b1n0] - Abort(338762383) (rank 34 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x149d46000000, scnts=0x2424e00, sdispls=0x240e400, dtype=0x4c000840, rbuf=0x149d46800000, rcnts=0x240e620, rdispls=0x240e730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x149d46000000, scnts=0x2424e00, sdispls=0x240e400, dtype=0x4c000840, rbuf=0x149d46800000, rcnts=0x240e620, rdispls=0x240e730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 33] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s37b1n0] - Abort(137435791) (rank 33 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14bc06000000, scnts=0x999db0, sdispls=0x9831e0, dtype=0x4c000840, rbuf=0x14bc06800000, rcnts=0x983400, rdispls=0x983510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14bc06000000, scnts=0x999db0, sdispls=0x9831e0, dtype=0x4c000840, rbuf=0x14bc06800000, rcnts=0x983400, rdispls=0x983510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 53] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3005c0s19b1n0] - Abort(942742159) (rank 53 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x148c34000000, scnts=0x1f25db0, sdispls=0x1f0f1e0, dtype=0x4c000840, rbuf=0x148c34800000, rcnts=0x1f0f400, rdispls=0x1f0f510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x148c34000000, scnts=0x1f25db0, sdispls=0x1f0f1e0, dtype=0x4c000840, rbuf=0x148c34800000, rcnts=0x1f0f400, rdispls=0x1f0f510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 13] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s25b0n0] - Abort(472980111) (rank 13 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14d786000000, scnts=0x1b68db0, sdispls=0x1b521e0, dtype=0x4c000840, rbuf=0x14d786810000, rcnts=0x1b52400, rdispls=0x1b52510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14d786000000, scnts=0x1b68db0, sdispls=0x1b521e0, dtype=0x4c000840, rbuf=0x14d786810000, rcnts=0x1b52400, rdispls=0x1b52510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 17] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s25b1n0] - Abort(674306703) (rank 17 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147954000000, scnts=0x109edb0, sdispls=0x10881e0, dtype=0x4c000840, rbuf=0x147954810000, rcnts=0x1088400, rdispls=0x1088510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147954000000, scnts=0x109edb0, sdispls=0x10881e0, dtype=0x4c000840, rbuf=0x147954810000, rcnts=0x1088400, rdispls=0x1088510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 4] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s1b0n0] - Abort(607197839) (rank 4 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f0e2000000, scnts=0x25b3ea0, sdispls=0x24aecd0, dtype=0x4c000840, rbuf=0x14f0e2810000, rcnts=0x24aeef0, rdispls=0x2564e60, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f0e2000000, scnts=0x25b3ea0, sdispls=0x24aecd0, dtype=0x4c000840, rbuf=0x14f0e2810000, rcnts=0x24aeef0, rdispls=0x2564e60, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 63] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3005c0s1b1n0] - Abort(405871247) (rank 63 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154726000000, scnts=0x1ee4db0, sdispls=0x1ece1e0, dtype=0x4c000840, rbuf=0x154726800000, rcnts=0x1ece400, rdispls=0x1ece510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154726000000, scnts=0x1ee4db0, sdispls=0x1ece1e0, dtype=0x4c000840, rbuf=0x154726800000, rcnts=0x1ece400, rdispls=0x1ece510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 37] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s7b0n0] - Abort(137435791) (rank 37 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14a506000000, scnts=0x2161db0, sdispls=0x214b1e0, dtype=0x4c000840, rbuf=0x14a506800000, rcnts=0x214b400, rdispls=0x214b510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14a506000000, scnts=0x2161db0, sdispls=0x214b1e0, dtype=0x4c000840, rbuf=0x14a506800000, rcnts=0x214b400, rdispls=0x214b510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 50] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3005c0s19b0n0] - Abort(405871247) (rank 50 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x148f32000000, scnts=0x169de00, sdispls=0x1687400, dtype=0x4c000840, rbuf=0x148f32800000, rcnts=0x1687620, rdispls=0x1687730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x148f32000000, scnts=0x169de00, sdispls=0x1687400, dtype=0x4c000840, rbuf=0x148f32800000, rcnts=0x1687620, rdispls=0x1687730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 29] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s37b0n0] - Abort(540088975) (rank 29 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14a216000000, scnts=0x251fdb0, sdispls=0x25091e0, dtype=0x4c000840, rbuf=0x14a216810000, rcnts=0x2509400, rdispls=0x2509510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14a216000000, scnts=0x251fdb0, sdispls=0x25091e0, dtype=0x4c000840, rbuf=0x14a216810000, rcnts=0x2509400, rdispls=0x2509510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 26] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s31b1n0] - Abort(942742159) (rank 26 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15425e000000, scnts=0x1b91e00, sdispls=0x1b7b400, dtype=0x4c000840, rbuf=0x15425e810000, rcnts=0x1b7b620, rdispls=0x1b7b730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15425e000000, scnts=0x1b91e00, sdispls=0x1b7b400, dtype=0x4c000840, rbuf=0x15425e810000, rcnts=0x1b7b620, rdispls=0x1b7b730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 23] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s31b0n0] - Abort(204544655) (rank 23 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x146284000000, scnts=0x1144db0, sdispls=0x112e1e0, dtype=0x4c000840, rbuf=0x146284810000, rcnts=0x112e400, rdispls=0x112e510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x146284000000, scnts=0x1144db0, sdispls=0x112e1e0, dtype=0x4c000840, rbuf=0x146284810000, rcnts=0x112e400, rdispls=0x112e510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 20] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s31b0n0] - Abort(741415567) (rank 20 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14fe6e000000, scnts=0x25c1ba0, sdispls=0x25c1ef0, dtype=0x4c000840, rbuf=0x14fe6e810000, rcnts=0x2440e20, rdispls=0x245e120, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14fe6e000000, scnts=0x25c1ba0, sdispls=0x25c1ef0, dtype=0x4c000840, rbuf=0x14fe6e810000, rcnts=0x2440e20, rdispls=0x245e120, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 15] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s25b0n0] - Abort(741415567) (rank 15 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x153ed4000000, scnts=0x1638db0, sdispls=0x16221e0, dtype=0x4c000840, rbuf=0x153ed4810000, rcnts=0x1622400, rdispls=0x1622510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x153ed4000000, scnts=0x1638db0, sdispls=0x16221e0, dtype=0x4c000840, rbuf=0x153ed4810000, rcnts=0x1622400, rdispls=0x1622510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 58] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3005c0s1b0n0] - Abort(472980111) (rank 58 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147cae000000, scnts=0x24e1e00, sdispls=0x24cb400, dtype=0x4c000840, rbuf=0x147cae800000, rcnts=0x24cb620, rdispls=0x24cb730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147cae000000, scnts=0x24e1e00, sdispls=0x24cb400, dtype=0x4c000840, rbuf=0x147cae800000, rcnts=0x24cb620, rdispls=0x24cb730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 16] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s25b1n0] - Abort(741415567) (rank 16 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14c656000000, scnts=0x1259bc0, sdispls=0x1237cf0, dtype=0x4c000840, rbuf=0x14c656810000, rcnts=0x137c100, rdispls=0x137c210, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14c656000000, scnts=0x1259bc0, sdispls=0x1237cf0, dtype=0x4c000840, rbuf=0x14c656810000, rcnts=0x137c100, rdispls=0x137c210, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 24] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s31b1n0] - Abort(70326927) (rank 24 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154ce4000000, scnts=0x10b2d40, sdispls=0x10bc500, dtype=0x4c000840, rbuf=0x154ce4810000, rcnts=0x10bc720, rdispls=0x10bc830, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154ce4000000, scnts=0x10b2d40, sdispls=0x10bc500, dtype=0x4c000840, rbuf=0x154ce4810000, rcnts=0x10bc720, rdispls=0x10bc830, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 14] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s25b0n0] - Abort(1009851023) (rank 14 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1461f6000000, scnts=0x187fe00, sdispls=0x1869400, dtype=0x4c000840, rbuf=0x1461f6810000, rcnts=0x1869620, rdispls=0x1869730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1461f6000000, scnts=0x187fe00, sdispls=0x1869400, dtype=0x4c000840, rbuf=0x1461f6810000, rcnts=0x1869620, rdispls=0x1869730, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 1] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s19b1n0] - Abort(808524431) (rank 1 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150b5e000000, scnts=0x2524e20, sdispls=0x250bcd0, dtype=0x4c000840, rbuf=0x150b5e810000, rcnts=0x250bef0, rdispls=0x250c000, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150b5e000000, scnts=0x2524e20, sdispls=0x250bcd0, dtype=0x4c000840, rbuf=0x150b5e810000, rcnts=0x250bef0, rdispls=0x250c000, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 48] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3005c0s19b0n0] - Abort(271653519) (rank 48 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15202e000000, scnts=0x10e5cb0, sdispls=0x10e7cd0, dtype=0x4c000840, rbuf=0x15202e800000, rcnts=0x10e7ef0, rdispls=0x121f0d0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15202e000000, scnts=0x10e5cb0, sdispls=0x10e7cd0, dtype=0x4c000840, rbuf=0x15202e800000, rcnts=0x10e7ef0, rdispls=0x121f0d0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 31] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s37b0n0] - Abort(741415567) (rank 31 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x145bc4000000, scnts=0xd52db0, sdispls=0xd3c1e0, dtype=0x4c000840, rbuf=0x145bc4810000, rcnts=0xd3c400, rdispls=0xd3c510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x145bc4000000, scnts=0xd52db0, sdispls=0xd3c1e0, dtype=0x4c000840, rbuf=0x145bc4810000, rcnts=0xd3c400, rdispls=0xd3c510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 56] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3005c0s1b0n0] - Abort(741415567) (rank 56 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f666000000, scnts=0x1b9b670, sdispls=0x1b9bf00, dtype=0x4c000840, rbuf=0x14f666800000, rcnts=0x1b7d8d0, rdispls=0x1b7d9e0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f666000000, scnts=0x1b9b670, sdispls=0x1b9bf00, dtype=0x4c000840, rbuf=0x14f666800000, rcnts=0x1b7d8d0, rdispls=0x1b7d9e0, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 19] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s25b1n0] - Abort(607197839) (rank 19 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150884000000, scnts=0x1792db0, sdispls=0x177c1e0, dtype=0x4c000840, rbuf=0x150884810000, rcnts=0x177c400, rdispls=0x177c510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150884000000, scnts=0x1792db0, sdispls=0x177c1e0, dtype=0x4c000840, rbuf=0x150884810000, rcnts=0x177c400, rdispls=0x177c510, datatype=dtype=0x4c000840, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 8] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s1b1n0] - Abort(204544655) (rank 8 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14d196000000, scnts=0xcb9c20, sdispls=0xc1d4e0, dtype=0x4c000840, rbuf=0x14d196810000, rcnts=0xc1d700, rdispls=0xc1d810, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14d196000000, scnts=0xcb9c20, sdispls=0xc1d4e0, dtype=0x4c000840, rbuf=0x14d196810000, rcnts=0xc1d700, rdispls=0xc1d810, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
x3004c0s7b0n0.hsn.cm.polaris.alcf.anl.gov: rank 38 exited with code 255
(GTL DEBUG: 36) cuIpcOpenMemHandle: invalid resource handle, CUDA_ERROR_INVALID_HANDLE, line no 272
MPICH ERROR [Rank 36] [job id 527e4b26-cd0b-4b77-bc03-b670afe1adb8] [Sun Nov 12 09:22:43 2023] [x3004c0s7b0n0] - Abort(4790786) (rank 36 in comm 0): Fatal error in PMPI_Alltoallv: Invalid count, error stack:
PMPI_Alltoallv(389)..................: MPI_Alltoallv(sbuf=0x14962e000000, scnts=0x1dd7ed0, sdispls=0x1ce1ef0, dtype=0x4c000840, rbuf=0x14962e800000, rcnts=0x1ce3210, rdispls=0x1ce3320, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1143)............: 
MPIC_Irecv(594)......................: 
MPID_Irecv(497)......................: 
MPIDI_irecv_unsafe(160)..............: 
MPIDI_SHM_mpi_irecv(462).............: 
MPIDI_SHM_mpi_imrecv(514)............: 
MPIDI_SHM_mmods_try_matched_recv(167): 
MPIDI_CRAY_Common_lmt_handle_recv(44): 
MPIDI_CRAY_Common_lmt_import_mem(218): 
(unknown)(): Invalid count

aborting job:
Fatal error in PMPI_Alltoallv: Invalid count, error stack:
PMPI_Alltoallv(389)..................: MPI_Alltoallv(sbuf=0x14962e000000, scnts=0x1dd7ed0, sdispls=0x1ce1ef0, dtype=0x4c000840, rbuf=0x14962e800000, rcnts=0x1ce3210, rdispls=0x1ce3320, datatype=dtype=0x4c000840, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1143)............: 
MPIC_Irecv(594)......................: 
MPID_Irecv(497)......................: 
MPIDI_irecv_unsafe(160)..............: 
MPIDI_SHM_mpi_irecv(462).............: 
MPIDI_SHM_mpi_imrecv(514)............: 
MPIDI_SHM_mmods_try_matched_recv(167): 
MPIDI_CRAY_Common_lmt_handle_recv(44): 
MPIDI_CRAY_Common_lmt_import_mem(218): 
(unknown)(): Invalid count
