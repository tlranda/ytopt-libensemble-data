“RANK= 48 LOCAL_RANK= 0 gpu= 3”
“RANK= 49 LOCAL_RANK= 1 gpu= 2”
“RANK= 50 LOCAL_RANK= 2 gpu= 1”
“RANK= 40 LOCAL_RANK= 0 gpu= 3”
“RANK= 51 LOCAL_RANK= 3 gpu= 0”
“RANK= 43 LOCAL_RANK= 3 gpu= 0”
“RANK= 41 LOCAL_RANK= 1 gpu= 2”
“RANK= 42 LOCAL_RANK= 2 gpu= 1”
“RANK= 24 LOCAL_RANK= 0 gpu= 3”
“RANK= 25 LOCAL_RANK= 1 gpu= 2”
“RANK= 27 LOCAL_RANK= 3 gpu= 0”
“RANK= 26 LOCAL_RANK= 2 gpu= 1”
“RANK= 52 LOCAL_RANK= 0 gpu= 3”
“RANK= 4 LOCAL_RANK= 0 gpu= 3”
“RANK= 5 LOCAL_RANK= 1 gpu= 2”
“RANK= 6 LOCAL_RANK= 2 gpu= 1”
“RANK= 54 LOCAL_RANK= 2 gpu= 1”
“RANK= 7 LOCAL_RANK= 3 gpu= 0”
“RANK= 37 LOCAL_RANK= 1 gpu= 2”
“RANK= 53 LOCAL_RANK= 1 gpu= 2”
“RANK= 36 LOCAL_RANK= 0 gpu= 3”
“RANK= 55 LOCAL_RANK= 3 gpu= 0”
“RANK= 8 LOCAL_RANK= 0 gpu= 3”
“RANK= 32 LOCAL_RANK= 0 gpu= 3”
“RANK= 9 LOCAL_RANK= 1 gpu= 2”
“RANK= 38 LOCAL_RANK= 2 gpu= 1”
“RANK= 33 LOCAL_RANK= 1 gpu= 2”
“RANK= 39 LOCAL_RANK= 3 gpu= 0”
“RANK= 11 LOCAL_RANK= 3 gpu= 0”
“RANK= 16 LOCAL_RANK= 0 gpu= 3”
“RANK= 18 LOCAL_RANK= 2 gpu= 1”
“RANK= 19 LOCAL_RANK= 3 gpu= 0”
“RANK= 10 LOCAL_RANK= 2 gpu= 1”
“RANK= 35 LOCAL_RANK= 3 gpu= 0”
“RANK= 34 LOCAL_RANK= 2 gpu= 1”
“RANK= 17 LOCAL_RANK= 1 gpu= 2”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
“RANK= 21 LOCAL_RANK= 1 gpu= 2”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
“RANK= 12 LOCAL_RANK= 0 gpu= 3”
“RANK= 20 LOCAL_RANK= 0 gpu= 3”
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
“RANK= 15 LOCAL_RANK= 3 gpu= 0”
“RANK= 23 LOCAL_RANK= 3 gpu= 0”
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
“RANK= 13 LOCAL_RANK= 1 gpu= 2”
“RANK= 22 LOCAL_RANK= 2 gpu= 1”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
“RANK= 14 LOCAL_RANK= 2 gpu= 1”
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
Shell debugging restarted
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -n x ']'
+ set +x
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
“RANK= 56 LOCAL_RANK= 0 gpu= 3”
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
“RANK= 57 LOCAL_RANK= 1 gpu= 2”
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
“RANK= 58 LOCAL_RANK= 2 gpu= 1”
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
“RANK= 59 LOCAL_RANK= 3 gpu= 0”
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
“RANK= 60 LOCAL_RANK= 0 gpu= 3”
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
“RANK= 61 LOCAL_RANK= 1 gpu= 2”
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ '[' -z '' ']'
+ case "$-" in
“RANK= 62 LOCAL_RANK= 2 gpu= 1”
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging restarted
+ unset __lmod_vx
“RANK= 29 LOCAL_RANK= 1 gpu= 2”
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
“RANK= 44 LOCAL_RANK= 0 gpu= 3”
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
“RANK= 63 LOCAL_RANK= 3 gpu= 0”
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
“RANK= 28 LOCAL_RANK= 0 gpu= 3”
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
“RANK= 46 LOCAL_RANK= 2 gpu= 1”
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
“RANK= 30 LOCAL_RANK= 2 gpu= 1”
“RANK= 45 LOCAL_RANK= 1 gpu= 2”
Shell debugging restarted
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging restarted
+ unset __lmod_vx
“RANK= 31 LOCAL_RANK= 3 gpu= 0”
“RANK= 47 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -z '' ']'
+ case "$-" in
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging restarted
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ set +x
Shell debugging restarted
+ unset __lmod_vx
“RANK= 0 LOCAL_RANK= 0 gpu= 3”
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
“RANK= 1 LOCAL_RANK= 1 gpu= 2”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
“RANK= 3 LOCAL_RANK= 3 gpu= 0”
“RANK= 2 LOCAL_RANK= 2 gpu= 1”
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
+ speed3d_r2c cufft float 512 512 512 -reorder -a2av -pencils -r2c_dir 2 -ingrid 2 2 16 -outgrid 8 8 1 -n5
MPICH ERROR [Rank 7] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3001c0s19b1n0] - Abort(875633295) (rank 7 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f556000000, scnts=0x1ae8640, sdispls=0x1b21b80, dtype=0x4c000840, rbuf=0x14f556808000, rcnts=0x1b21da0, rdispls=0x1b21eb0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f556000000, scnts=0x1ae8640, sdispls=0x1b21b80, dtype=0x4c000840, rbuf=0x14f556808000, rcnts=0x1b21da0, rdispls=0x1b21eb0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 59] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3002c0s19b0n0] - Abort(137435791) (rank 59 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x153d0e000000, scnts=0x2030640, sdispls=0x2069b80, dtype=0x4c000840, rbuf=0x153d0e808000, rcnts=0x2069da0, rdispls=0x2069eb0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x153d0e000000, scnts=0x2030640, sdispls=0x2069b80, dtype=0x4c000840, rbuf=0x153d0e808000, rcnts=0x2069da0, rdispls=0x2069eb0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 55] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3002c0s13b1n0] - Abort(271653519) (rank 55 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154a2e000000, scnts=0x174f640, sdispls=0x1788b80, dtype=0x4c000840, rbuf=0x154a2e808000, rcnts=0x1788da0, rdispls=0x1788eb0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154a2e000000, scnts=0x174f640, sdispls=0x1788b80, dtype=0x4c000840, rbuf=0x154a2e808000, rcnts=0x1788da0, rdispls=0x1788eb0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 10] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3001c0s1b0n0] - Abort(271653519) (rank 10 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x145f66000000, scnts=0x14a2380, sdispls=0x14a31c0, dtype=0x4c000840, rbuf=0x145f66808000, rcnts=0x14a33e0, rdispls=0x14a34f0, datatype=dtype=0x4c000840, comm=comm=0xc4000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x145f66000000, scnts=0x14a2380, sdispls=0x14a31c0, dtype=0x4c000840, rbuf=0x145f66808000, rcnts=0x14a33e0, rdispls=0x14a34f0, datatype=dtype=0x4c000840, comm=comm=0xc4000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 19] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3001c0s25b0n0] - Abort(3218063) (rank 19 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14eae0000000, scnts=0x165b640, sdispls=0x1694b80, dtype=0x4c000840, rbuf=0x14eae0808000, rcnts=0x1694da0, rdispls=0x1694eb0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14eae0000000, scnts=0x165b640, sdispls=0x1694b80, dtype=0x4c000840, rbuf=0x14eae0808000, rcnts=0x1694da0, rdispls=0x1694eb0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 27] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3001c0s31b0n0] - Abort(1009851023) (rank 27 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154276000000, scnts=0x17f2640, sdispls=0x182bb80, dtype=0x4c000840, rbuf=0x154276808000, rcnts=0x182bda0, rdispls=0x182beb0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154276000000, scnts=0x17f2640, sdispls=0x182bb80, dtype=0x4c000840, rbuf=0x154276808000, rcnts=0x182bda0, rdispls=0x182beb0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 32] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3001c0s37b0n0] - Abort(472980111) (rank 32 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14d9c4000000, scnts=0x23860e0, sdispls=0x23c2270, dtype=0x4c000840, rbuf=0x14d9c4808000, rcnts=0x23c2490, rdispls=0x23c25a0, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14d9c4000000, scnts=0x23860e0, sdispls=0x23c2270, dtype=0x4c000840, rbuf=0x14d9c4808000, rcnts=0x23c2490, rdispls=0x23c25a0, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 36] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3001c0s37b1n0] - Abort(70326927) (rank 36 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1545ce000000, scnts=0x1b62e70, sdispls=0x1b9c270, dtype=0x4c000840, rbuf=0x1545ce808000, rcnts=0x1b9c490, rdispls=0x1b9c5a0, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1545ce000000, scnts=0x1b62e70, sdispls=0x1b9c270, dtype=0x4c000840, rbuf=0x1545ce808000, rcnts=0x1b9c490, rdispls=0x1b9c5a0, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 25] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3001c0s31b0n0] - Abort(405871247) (rank 25 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x152f74000000, scnts=0x234a380, sdispls=0x234b1c0, dtype=0x4c000840, rbuf=0x152f74808000, rcnts=0x234b3e0, rdispls=0x234b4f0, datatype=dtype=0x4c000840, comm=comm=0xc4000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x152f74000000, scnts=0x234a380, sdispls=0x234b1c0, dtype=0x4c000840, rbuf=0x152f74808000, rcnts=0x234b3e0, rdispls=0x234b4f0, datatype=dtype=0x4c000840, comm=comm=0xc4000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
x3001c0s19b1n0.hsn.cm.polaris.alcf.anl.gov: rank 7 exited with code 255
MPICH ERROR [Rank 50] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3002c0s13b0n0] - Abort(137435791) (rank 50 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14d5e6000000, scnts=0xc1e380, sdispls=0xc1f1c0, dtype=0x4c000840, rbuf=0x14d5e6808000, rcnts=0xc1f3e0, rdispls=0xc1f4f0, datatype=dtype=0x4c000840, comm=comm=0xc4000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote invalid request error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14d5e6000000, scnts=0xc1e380, sdispls=0xc1f1c0, dtype=0x4c000840, rbuf=0x14d5e6808000, rcnts=0xc1f3e0, rdispls=0xc1f4f0, datatype=dtype=0x4c000840, comm=comm=0xc4000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote invalid request error)
MPICH ERROR [Rank 56] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3002c0s19b0n0] - Abort(540088975) (rank 56 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14d364000000, scnts=0x2292e10, sdispls=0x22ac270, dtype=0x4c000840, rbuf=0x14d364808000, rcnts=0x22ac490, rdispls=0x22ac5a0, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14d364000000, scnts=0x2292e10, sdispls=0x22ac270, dtype=0x4c000840, rbuf=0x14d364808000, rcnts=0x22ac490, rdispls=0x22ac5a0, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 1] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3001c0s19b0n0] - Abort(741415567) (rank 1 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1462d6000000, scnts=0xdbeea0, sdispls=0xddfce0, dtype=0x4c000840, rbuf=0x1462d6808000, rcnts=0xddff00, rdispls=0xde0010, datatype=dtype=0x4c000840, comm=comm=0xc4000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1462d6000000, scnts=0xdbeea0, sdispls=0xddfce0, dtype=0x4c000840, rbuf=0x1462d6808000, rcnts=0xddff00, rdispls=0xde0010, datatype=dtype=0x4c000840, comm=comm=0xc4000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 12] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3001c0s1b1n0] - Abort(137435791) (rank 12 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14dec6000000, scnts=0x208de50, sdispls=0x208f290, dtype=0x4c000840, rbuf=0x14dec6808000, rcnts=0x208f4b0, rdispls=0x208f5c0, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote invalid request error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14dec6000000, scnts=0x208de50, sdispls=0x208f290, dtype=0x4c000840, rbuf=0x14dec6808000, rcnts=0x208f4b0, rdispls=0x208f5c0, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote invalid request error)
MPICH ERROR [Rank 15] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3001c0s1b1n0] - Abort(942742159) (rank 15 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1469de000000, scnts=0x19ad640, sdispls=0x19e6b80, dtype=0x4c000840, rbuf=0x1469de808000, rcnts=0x19e6da0, rdispls=0x19e6eb0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1469de000000, scnts=0x19ad640, sdispls=0x19e6b80, dtype=0x4c000840, rbuf=0x1469de808000, rcnts=0x19e6da0, rdispls=0x19e6eb0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 53] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3002c0s13b1n0] - Abort(808000015) (rank 53 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389).........: MPI_Alltoallv(sbuf=0x1491ce000000, scnts=0x1f109f0, sdispls=0x1ef42c0, dtype=0x4c000840, rbuf=0x1491ce800000, rcnts=0x1ef44e0, rdispls=0x1ef45f0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1155)...: 
MPIC_Isend(511).............: 
MPID_Isend_coll(610)........: 
MPIDI_isend_coll_unsafe(176): 
MPIDI_OFI_send_normal(352)..: OFI tagged senddata failed (ofi_send.h:352:MPIDI_OFI_send_normal:No route to host)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389).........: MPI_Alltoallv(sbuf=0x1491ce000000, scnts=0x1f109f0, sdispls=0x1ef42c0, dtype=0x4c000840, rbuf=0x1491ce800000, rcnts=0x1ef44e0, rdispls=0x1ef45f0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1155)...: 
MPIC_Isend(511).............: 
MPID_Isend_coll(610)........: 
MPIDI_isend_coll_unsafe(176): 
MPIDI_OFI_send_normal(352)..: OFI tagged senddata failed (ofi_send.h:352:MPIDI_OFI_send_normal:No route to host)
MPICH ERROR [Rank 30] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3001c0s31b1n0] - Abort(673782287) (rank 30 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389).........: MPI_Alltoallv(sbuf=0x14a694000000, scnts=0x11949f0, sdispls=0x11782c0, dtype=0x4c000840, rbuf=0x14a694800000, rcnts=0x11784e0, rdispls=0x11785f0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1155)...: 
MPIC_Isend(511).............: 
MPID_Isend_coll(610)........: 
MPIDI_isend_coll_unsafe(176): 
MPIDI_OFI_send_normal(352)..: OFI tagged senddata failed (ofi_send.h:352:MPIDI_OFI_send_normal:No route to host)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389).........: MPI_Alltoallv(sbuf=0x14a694000000, scnts=0x11949f0, sdispls=0x11782c0, dtype=0x4c000840, rbuf=0x14a694800000, rcnts=0x11784e0, rdispls=0x11785f0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1155)...: 
MPIC_Isend(511).............: 
MPID_Isend_coll(610)........: 
MPIDI_isend_coll_unsafe(176): 
MPIDI_OFI_send_normal(352)..: OFI tagged senddata failed (ofi_send.h:352:MPIDI_OFI_send_normal:No route to host)
MPICH ERROR [Rank 37] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3001c0s37b1n0] - Abort(808524431) (rank 37 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147e66000000, scnts=0x121f380, sdispls=0x12201c0, dtype=0x4c000840, rbuf=0x147e66808000, rcnts=0x12203e0, rdispls=0x12204f0, datatype=dtype=0x4c000840, comm=comm=0xc4000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147e66000000, scnts=0x121f380, sdispls=0x12201c0, dtype=0x4c000840, rbuf=0x147e66808000, rcnts=0x12203e0, rdispls=0x12204f0, datatype=dtype=0x4c000840, comm=comm=0xc4000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 39] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3001c0s37b1n0] - Abort(942742159) (rank 39 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14808e000000, scnts=0x2578640, sdispls=0x25b1b80, dtype=0x4c000840, rbuf=0x14808e808000, rcnts=0x25b1da0, rdispls=0x25b1eb0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14808e000000, scnts=0x2578640, sdispls=0x25b1b80, dtype=0x4c000840, rbuf=0x14808e808000, rcnts=0x25b1da0, rdispls=0x25b1eb0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 43] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3001c0s7b0n0] - Abort(338762383) (rank 43 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150ea6000000, scnts=0x217c640, sdispls=0x21b5b80, dtype=0x4c000840, rbuf=0x150ea6808000, rcnts=0x21b5da0, rdispls=0x21b5eb0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x150ea6000000, scnts=0x217c640, sdispls=0x21b5b80, dtype=0x4c000840, rbuf=0x150ea6808000, rcnts=0x21b5da0, rdispls=0x21b5eb0, datatype=dtype=0x4c000840, comm=comm=0xc4000005) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 16] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3001c0s25b0n0] - Abort(674306703) (rank 16 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14fcf6000000, scnts=0x1968440, sdispls=0x19a4700, dtype=0x4c000840, rbuf=0x14fcf6808000, rcnts=0x19a4920, rdispls=0x19a4a30, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14fcf6000000, scnts=0x1968440, sdispls=0x19a4700, dtype=0x4c000840, rbuf=0x14fcf6808000, rcnts=0x19a4920, rdispls=0x19a4a30, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 17] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3001c0s25b0n0] - Abort(808524431) (rank 17 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14fc66000000, scnts=0xa60380, sdispls=0xa611c0, dtype=0x4c000840, rbuf=0x14fc66808000, rcnts=0xa613e0, rdispls=0xa614f0, datatype=dtype=0x4c000840, comm=comm=0xc4000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14fc66000000, scnts=0xa60380, sdispls=0xa611c0, dtype=0x4c000840, rbuf=0x14fc66808000, rcnts=0xa613e0, rdispls=0xa614f0, datatype=dtype=0x4c000840, comm=comm=0xc4000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 42] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3001c0s7b0n0] - Abort(942742159) (rank 42 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1481be000000, scnts=0x2646380, sdispls=0x26471c0, dtype=0x4c000840, rbuf=0x1481be808000, rcnts=0x26473e0, rdispls=0x26474f0, datatype=dtype=0x4c000840, comm=comm=0xc4000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1481be000000, scnts=0x2646380, sdispls=0x26471c0, dtype=0x4c000840, rbuf=0x1481be808000, rcnts=0x26473e0, rdispls=0x26474f0, datatype=dtype=0x4c000840, comm=comm=0xc4000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 20] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3001c0s25b1n0] - Abort(137435791) (rank 20 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1554e4000000, scnts=0xb5be50, sdispls=0xb77270, dtype=0x4c000840, rbuf=0x1554e4808000, rcnts=0xb77490, rdispls=0xb775a0, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1554e4000000, scnts=0xb5be50, sdispls=0xb77270, dtype=0x4c000840, rbuf=0x1554e4808000, rcnts=0xb77490, rdispls=0xb775a0, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 28] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3001c0s31b1n0] - Abort(540088975) (rank 28 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x153a06000000, scnts=0x14218f0, sdispls=0x1566b90, dtype=0x4c000840, rbuf=0x153a06808000, rcnts=0x1566db0, rdispls=0x1566ec0, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x153a06000000, scnts=0x14218f0, sdispls=0x1566b90, dtype=0x4c000840, rbuf=0x153a06808000, rcnts=0x1566db0, rdispls=0x1566ec0, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 13] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3001c0s1b1n0] - Abort(3218063) (rank 13 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14ed86000000, scnts=0x1c2a380, sdispls=0x1c2b1c0, dtype=0x4c000840, rbuf=0x14ed86808000, rcnts=0x1c2b3e0, rdispls=0x1c2b4f0, datatype=dtype=0x4c000840, comm=comm=0xc4000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14ed86000000, scnts=0x1c2a380, sdispls=0x1c2b1c0, dtype=0x4c000840, rbuf=0x14ed86808000, rcnts=0x1c2b3e0, rdispls=0x1c2b4f0, datatype=dtype=0x4c000840, comm=comm=0xc4000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 8] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:23:52 2023] [x3001c0s1b0n0] - Abort(540088975) (rank 8 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x151d56000000, scnts=0x12b77d0, sdispls=0x1295970, dtype=0x4c000840, rbuf=0x151d56808000, rcnts=0x1295b90, rdispls=0x1295ca0, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x151d56000000, scnts=0x12b77d0, sdispls=0x1295970, dtype=0x4c000840, rbuf=0x151d56808000, rcnts=0x1295b90, rdispls=0x1295ca0, datatype=dtype=0x4c000840, comm=comm=0xc400000b) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 21] [job id 95bc8f77-e3ef-4d58-b500-0f9411f2f023] [Sun Nov 12 09:24:26 2023] [x3001c0s25b1n0] - Abort(3218063) (rank 21 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14d4c6000000, scnts=0x1ca1380, sdispls=0x1ca21c0, dtype=0x4c000840, rbuf=0x14d4c6808000, rcnts=0x1ca23e0, rdispls=0x1ca24f0, datatype=dtype=0x4c000840, comm=comm=0xc4000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - transport retry counter exceeded)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14d4c6000000, scnts=0x1ca1380, sdispls=0x1ca21c0, dtype=0x4c000840, rbuf=0x14d4c6808000, rcnts=0x1ca23e0, rdispls=0x1ca24f0, datatype=dtype=0x4c000840, comm=comm=0xc4000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - transport retry counter exceeded)
