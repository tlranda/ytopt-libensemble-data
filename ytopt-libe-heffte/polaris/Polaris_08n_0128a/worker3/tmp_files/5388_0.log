“RANK= 5 LOCAL_RANK= 1 gpu= 2”
“RANK= 6 LOCAL_RANK= 2 gpu= 1”
“RANK= 7 LOCAL_RANK= 3 gpu= 0”
“RANK= 4 LOCAL_RANK= 0 gpu= 3”
“RANK= 20 LOCAL_RANK= 0 gpu= 3”
“RANK= 21 LOCAL_RANK= 1 gpu= 2”
“RANK= 23 LOCAL_RANK= 3 gpu= 0”
“RANK= 22 LOCAL_RANK= 2 gpu= 1”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
“RANK= 12 LOCAL_RANK= 0 gpu= 3”
“RANK= 14 LOCAL_RANK= 2 gpu= 1”
“RANK= 13 LOCAL_RANK= 1 gpu= 2”
“RANK= 15 LOCAL_RANK= 3 gpu= 0”
“RANK= 28 LOCAL_RANK= 0 gpu= 3”
“RANK= 24 LOCAL_RANK= 0 gpu= 3”
“RANK= 25 LOCAL_RANK= 1 gpu= 2”
“RANK= 29 LOCAL_RANK= 1 gpu= 2”
“RANK= 31 LOCAL_RANK= 3 gpu= 0”
“RANK= 30 LOCAL_RANK= 2 gpu= 1”
“RANK= 27 LOCAL_RANK= 3 gpu= 0”
“RANK= 26 LOCAL_RANK= 2 gpu= 1”
“RANK= 11 LOCAL_RANK= 3 gpu= 0”
“RANK= 8 LOCAL_RANK= 0 gpu= 3”
“RANK= 9 LOCAL_RANK= 1 gpu= 2”
“RANK= 10 LOCAL_RANK= 2 gpu= 1”
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
+ '[' -z '' ']'
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ set +x
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
“RANK= 16 LOCAL_RANK= 0 gpu= 3”
“RANK= 17 LOCAL_RANK= 1 gpu= 2”
“RANK= 19 LOCAL_RANK= 3 gpu= 0”
“RANK= 18 LOCAL_RANK= 2 gpu= 1”
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
“RANK= 1 LOCAL_RANK= 1 gpu= 2”
“RANK= 0 LOCAL_RANK= 0 gpu= 3”
“RANK= 2 LOCAL_RANK= 2 gpu= 1”
“RANK= 3 LOCAL_RANK= 3 gpu= 0”
+ '[' -z '' ']'
+ case "$-" in
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ '[' -n x ']'
+ set +x
Shell debugging restarted
+ unset __lmod_vx
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ '[' -z '' ']'
+ case "$-" in
+ __lmod_vx=x
+ '[' -n x ']'
+ set +x
+ '[' -n x ']'
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
+ set +x
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for this output (/usr/share/lmod/lmod/init/bash)
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
Shell debugging restarted
+ unset __lmod_vx
Shell debugging restarted
+ unset __lmod_vx
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
+ speed3d_r2c cufft double 128 128 128 -no-reorder -a2av -slabs -r2c_dir 2 -ingrid 8 4 1 -n5
MPICH ERROR [Rank 9] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:14:59 2023] [x3208c0s1b0n0] - Abort(204544655) (rank 9 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1545f3800000, scnts=0xadd870, sdispls=0xaddb00, dtype=0x4c001041, rbuf=0x1545f3880000, rcnts=0xaddb60, rdispls=0xaddd90, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1545f3800000, scnts=0xadd870, sdispls=0xaddb00, dtype=0x4c001041, rbuf=0x1545f3880000, rcnts=0xaddb60, rdispls=0xaddd90, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 10] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:14:59 2023] [x3208c0s1b0n0] - Abort(70326927) (rank 10 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1471e3800000, scnts=0xaf0540, sdispls=0xaf09b0, dtype=0x4c001041, rbuf=0x1471e3880000, rcnts=0xaf0a10, rdispls=0xaf0c90, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1471e3800000, scnts=0xaf0540, sdispls=0xaf09b0, dtype=0x4c001041, rbuf=0x1471e3880000, rcnts=0xaf0a10, rdispls=0xaf0c90, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 13] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:14:59 2023] [x3208c0s1b1n0] - Abort(472980111) (rank 13 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154481800000, scnts=0x122fa80, sdispls=0x122fea0, dtype=0x4c001041, rbuf=0x154481880000, rcnts=0x122ff00, rdispls=0x1230130, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x154481800000, scnts=0x122fa80, sdispls=0x122fea0, dtype=0x4c001041, rbuf=0x154481880000, rcnts=0x122ff00, rdispls=0x1230130, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 14] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:14:59 2023] [x3208c0s1b1n0] - Abort(1009851023) (rank 14 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147563800000, scnts=0x100ca50, sdispls=0x100ce70, dtype=0x4c001041, rbuf=0x147563880000, rcnts=0x100ced0, rdispls=0x100d150, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147563800000, scnts=0x100ca50, sdispls=0x100ce70, dtype=0x4c001041, rbuf=0x147563880000, rcnts=0x100ced0, rdispls=0x100d150, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 12] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:14:59 2023] [x3208c0s1b1n0] - Abort(405871247) (rank 12 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1505e3800000, scnts=0x13a4100, sdispls=0x13a4570, dtype=0x4c001041, rbuf=0x1505e3880000, rcnts=0x13a45d0, rdispls=0x13a4ae0, datatype=dtype=0x4c001041, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1505e3800000, scnts=0x13a4100, sdispls=0x13a4570, dtype=0x4c001041, rbuf=0x1505e3880000, rcnts=0x13a45d0, rdispls=0x13a4ae0, datatype=dtype=0x4c001041, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 15] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:14:59 2023] [x3208c0s1b1n0] - Abort(472980111) (rank 15 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x149df3800000, scnts=0xf37d00, sdispls=0xf38120, dtype=0x4c001041, rbuf=0x149df3880000, rcnts=0xf38180, rdispls=0xf383b0, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x149df3800000, scnts=0xf37d00, sdispls=0xf38120, dtype=0x4c001041, rbuf=0x149df3880000, rcnts=0xf38180, rdispls=0xf383b0, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 3] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:14:59 2023] [x3208c0s13b1n0] - Abort(137435791) (rank 3 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1494d3800000, scnts=0x172bb30, sdispls=0x172bf50, dtype=0x4c001041, rbuf=0x1494d3888000, rcnts=0x172bfb0, rdispls=0x172c1e0, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1494d3800000, scnts=0x172bb30, sdispls=0x172bf50, dtype=0x4c001041, rbuf=0x1494d3888000, rcnts=0x172bfb0, rdispls=0x172c1e0, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 5] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:14:59 2023] [x3208c0s19b0n0] - Abort(472980111) (rank 5 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147613800000, scnts=0x25fa570, sdispls=0x25fa990, dtype=0x4c001041, rbuf=0x147613888000, rcnts=0x25fa9f0, rdispls=0x25fac20, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147613800000, scnts=0x25fa570, sdispls=0x25fa990, dtype=0x4c001041, rbuf=0x147613888000, rcnts=0x25fa9f0, rdispls=0x25fac20, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 7] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:14:59 2023] [x3208c0s19b0n0] - Abort(204544655) (rank 7 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f651800000, scnts=0x20329f0, sdispls=0x2032e60, dtype=0x4c001041, rbuf=0x14f651888000, rcnts=0x2032ec0, rdispls=0x2033140, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f651800000, scnts=0x20329f0, sdispls=0x2032e60, dtype=0x4c001041, rbuf=0x14f651888000, rcnts=0x2032ec0, rdispls=0x2033140, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 2] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:15:00 2023] [x3208c0s13b1n0] - Abort(942742159) (rank 2 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f113800000, scnts=0x8ccca0, sdispls=0x8cd0c0, dtype=0x4c001041, rbuf=0x14f113888000, rcnts=0x8cd120, rdispls=0x8cd350, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f113800000, scnts=0x8ccca0, sdispls=0x8cd0c0, dtype=0x4c001041, rbuf=0x14f113888000, rcnts=0x8cd120, rdispls=0x8cd350, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 6] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:15:00 2023] [x3208c0s19b0n0] - Abort(540088975) (rank 6 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15498b800000, scnts=0x252f650, sdispls=0x252f5f0, dtype=0x4c001041, rbuf=0x15498b888000, rcnts=0x252f930, rdispls=0x252f960, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x15498b800000, scnts=0x252f650, sdispls=0x252f5f0, dtype=0x4c001041, rbuf=0x15498b888000, rcnts=0x252f930, rdispls=0x252f960, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 4] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:15:00 2023] [x3208c0s19b0n0] - Abort(741415567) (rank 4 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f941800000, scnts=0x275c5c0, sdispls=0x275ca30, dtype=0x4c001041, rbuf=0x14f941888000, rcnts=0x275ca90, rdispls=0x275cfa0, datatype=dtype=0x4c001041, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14f941800000, scnts=0x275c5c0, sdispls=0x275ca30, dtype=0x4c001041, rbuf=0x14f941888000, rcnts=0x275ca90, rdispls=0x275cfa0, datatype=dtype=0x4c001041, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - local protection error)
MPICH ERROR [Rank 29] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:15:00 2023] [x3208c0s31b1n0] - Abort(405871247) (rank 29 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x148e33800000, scnts=0x2633eb0, sdispls=0x25f6650, dtype=0x4c001041, rbuf=0x148e33880000, rcnts=0x25f66b0, rdispls=0x25f6930, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x148e33800000, scnts=0x2633eb0, sdispls=0x25f6650, dtype=0x4c001041, rbuf=0x148e33880000, rcnts=0x25f66b0, rdispls=0x25f6930, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 25] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:15:00 2023] [x3208c0s31b0n0] - Abort(1009851023) (rank 25 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147841800000, scnts=0x10f8390, sdispls=0x10f8800, dtype=0x4c001041, rbuf=0x147841880000, rcnts=0x10f8860, rdispls=0x10f8ae0, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147841800000, scnts=0x10f8390, sdispls=0x10f8800, dtype=0x4c001041, rbuf=0x147841880000, rcnts=0x10f8860, rdispls=0x10f8ae0, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 24] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:15:00 2023] [x3208c0s31b0n0] - Abort(472980111) (rank 24 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147c31800000, scnts=0x256c820, sdispls=0x256cc90, dtype=0x4c001041, rbuf=0x147c31880000, rcnts=0x256ccf0, rdispls=0x2589460, datatype=dtype=0x4c001041, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x147c31800000, scnts=0x256c820, sdispls=0x256cc90, dtype=0x4c001041, rbuf=0x147c31880000, rcnts=0x256ccf0, rdispls=0x2589460, datatype=dtype=0x4c001041, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 27] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:15:00 2023] [x3208c0s31b0n0] - Abort(271653519) (rank 27 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1494db800000, scnts=0x1bfa600, sdispls=0x1bfa5a0, dtype=0x4c001041, rbuf=0x1494db880000, rcnts=0x1bfa8e0, rdispls=0x1bfa910, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1494db800000, scnts=0x1bfa600, sdispls=0x1bfa5a0, dtype=0x4c001041, rbuf=0x1494db880000, rcnts=0x1bfa8e0, rdispls=0x1bfa910, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 26] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:15:00 2023] [x3208c0s31b0n0] - Abort(808524431) (rank 26 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14cce1800000, scnts=0x10fcf70, sdispls=0x10bf650, dtype=0x4c001041, rbuf=0x14cce1880000, rcnts=0x10bf6b0, rdispls=0x10bf930, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14cce1800000, scnts=0x10fcf70, sdispls=0x10bf650, dtype=0x4c001041, rbuf=0x14cce1880000, rcnts=0x10bf6b0, rdispls=0x10bf930, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 23] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:15:00 2023] [x3208c0s25b1n0] - Abort(540088975) (rank 23 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14b3fb800000, scnts=0xd5cfb0, sdispls=0xd3b5d0, dtype=0x4c001041, rbuf=0x14b3fb880000, rcnts=0xd3b630, rdispls=0xd3b8b0, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14b3fb800000, scnts=0xd5cfb0, sdispls=0xd3b5d0, dtype=0x4c001041, rbuf=0x14b3fb880000, rcnts=0xd3b630, rdispls=0xd3b8b0, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 21] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:15:00 2023] [x3208c0s25b1n0] - Abort(741415567) (rank 21 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1476f1800000, scnts=0x1054390, sdispls=0x10547b0, dtype=0x4c001041, rbuf=0x1476f1880000, rcnts=0x1054810, rdispls=0x1054a90, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x1476f1800000, scnts=0x1054390, sdispls=0x10547b0, dtype=0x4c001041, rbuf=0x1476f1880000, rcnts=0x1054810, rdispls=0x1054a90, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 22] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:15:00 2023] [x3208c0s25b1n0] - Abort(808524431) (rank 22 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14cafb800000, scnts=0x199ba60, sdispls=0x199bed0, dtype=0x4c001041, rbuf=0x14cafb880000, rcnts=0x199bf30, rdispls=0x199c1b0, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14cafb800000, scnts=0x199ba60, sdispls=0x199bed0, dtype=0x4c001041, rbuf=0x14cafb880000, rcnts=0x199bf30, rdispls=0x199c1b0, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 20] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:15:00 2023] [x3208c0s25b1n0] - Abort(607197839) (rank 20 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x153c41800000, scnts=0x23ce260, sdispls=0x23ce6d0, dtype=0x4c001041, rbuf=0x153c41880000, rcnts=0x23ce730, rdispls=0x23cec40, datatype=dtype=0x4c001041, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x153c41800000, scnts=0x23ce260, sdispls=0x23ce6d0, dtype=0x4c001041, rbuf=0x153c41880000, rcnts=0x23ce730, rdispls=0x23cec40, datatype=dtype=0x4c001041, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 16] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:15:00 2023] [x3208c0s25b0n0] - Abort(271653519) (rank 16 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14edf3800000, scnts=0x8d6600, sdispls=0x8d6a70, dtype=0x4c001041, rbuf=0x14edf3880000, rcnts=0x8d6ad0, rdispls=0x8d6fe0, datatype=dtype=0x4c001041, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x14edf3800000, scnts=0x8d6600, sdispls=0x8d6a70, dtype=0x4c001041, rbuf=0x14edf3880000, rcnts=0x8d6ad0, rdispls=0x8d6fe0, datatype=dtype=0x4c001041, comm=comm=0xc4000003) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 19] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:15:00 2023] [x3208c0s25b0n0] - Abort(1009851023) (rank 19 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x145e81800000, scnts=0x1335dd0, sdispls=0x12f8470, dtype=0x4c001041, rbuf=0x145e81880000, rcnts=0x12f84d0, rdispls=0x12f8750, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x145e81800000, scnts=0x1335dd0, sdispls=0x12f8470, dtype=0x4c001041, rbuf=0x145e81880000, rcnts=0x12f84d0, rdispls=0x12f8750, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
MPICH ERROR [Rank 18] [job id 3aa836d5-245d-4d84-8be1-700ba3b4de95] [Thu Aug  3 06:15:00 2023] [x3208c0s25b0n0] - Abort(607197839) (rank 18 in comm 0): Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x152513800000, scnts=0x13243c0, sdispls=0x13247e0, dtype=0x4c001041, rbuf=0x152513880000, rcnts=0x1324840, rdispls=0x1324a70, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)

aborting job:
Fatal error in PMPI_Alltoallv: Other MPI error, error stack:
PMPI_Alltoallv(389)............: MPI_Alltoallv(sbuf=0x152513800000, scnts=0x13243c0, sdispls=0x13247e0, dtype=0x4c001041, rbuf=0x152513880000, rcnts=0x1324840, rdispls=0x1324a70, datatype=dtype=0x4c001041, comm=comm=0x84000007) failed
MPIR_CRAY_Alltoallv(1162)......: 
MPIR_Waitall(167)..............: 
MPIR_Waitall_impl(51)..........: 
MPID_Progress_wait(184)........: 
MPIDI_Progress_test(80)........: 
MPIDI_OFI_handle_cq_error(1059): OFI poll failed (ofi_events.c:1061:MPIDI_OFI_handle_cq_error:Input/output error - remote access error)
x3208c0s1b0n0.hsn.cm.polaris.alcf.anl.gov: rank 9 exited with code 255
